{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# [WIP #138986545] LDAを使って質問文の意味解析をする\n",
    "\n",
    "LDAで意味解析すると何が出来るのかを調査します。\n",
    "\n",
    "## scikit-learn の LDAで出来ること\n",
    "\n",
    "まずは手始めに、何が出来るのかを調べてみました。\n",
    "\n",
    "- 次元削除\n",
    "\n",
    " 入力となるデータセットは、ラベルがついている必要があります（すなわち教師ありきのデータが必要）。\n",
    "\n",
    " あとは SVM などと同じように、ラベル付きデータセット（リストイメージ）を入力とし、結果予測を行います。\n",
    " \n",
    " 出力はラベルが含まれる確率がリストイメージで戻るものとの想定です（これは実機検証予定です）。\n",
    "\n",
    " 評価指標としては homogeneity_score（分類の良し悪し）というのがあるようです。\n",
    "\n",
    " 基本的にはデータセットの次元が削除されることにより、カテゴリーを絞り込みするのに使える手法との認識です。\n",
    " \n",
    " すなわち SVM のフロントエンド（＝辞書構築など）として使えそう？　といったのが現時点でのイメージです。\n",
    "\n",
    "\n",
    "- 調査観点\n",
    "\n",
    " 下記のようなところかと考えています。（後日、変わる可能性はあります）\n",
    " \n",
    " (1) 意味解析じたいに使えるのか？\n",
    " \n",
    " （公式ページやWeb上の記事などを見た感じでは、ちょっと違う感じがするのですが・・・とりあえず進めてみます）\n",
    " \n",
    " (2) SVMなどの教師ありき学習機能の補完機能として使えそうか？\n",
    " \n",
    " （イメージとしてはこちらの方が当たっている感じ）\n",
    " \n",
    " \n",
    "## ほかのツールを使用した LDA\n",
    "\n",
    "- gensim\n",
    "\n",
    " これも次元削除や辞書構築用のツールとして使えるようです。\n",
    " \n",
    " ラベル付きデータセットを入力し、ラベルが含まれる確率がリストイメージで出力されるイメージかと存じます。\n",
    " \n",
    " （scikit-learn の LDA でこれが出来るのであれば不要です）\n",
    "\n",
    "\n",
    "## テストデータ／サンプルコードを使って検証\n",
    "\n",
    "後日検証いたします。\n",
    "\n",
    "- scikit-learn のサンプルを動かしてみます\n",
    "\n",
    "\n",
    "- テストデータを使用した次元削除処理のイメージ\n",
    "\n",
    "\n",
    "- テストデータを使用した辞書構築処理のイメージ\n",
    "\n",
    "\n",
    "- （その他、できることが新たに判明し次第、検証項目を追加します）\n",
    "\n",
    "\n",
    "## 参考文献\n",
    "\n",
    "### 公式ドキュメント\n",
    "\n",
    "http://scikit-learn.org/stable/modules/lda_qda.html\n",
    "\n",
    "### Web上のドキュメント\n",
    "\n",
    "- 次元削除についてのコメントと例\n",
    "\n",
    " http://cheminformist.itmol.com/TEST/wp-content/uploads/2015/04/Dimensionality_Reduction.html\n",
    " \n",
    " \n",
    "## 気がついたこと（後日検討）\n",
    "\n",
    "### 教師なしデータの分析\n",
    "\n",
    "以下は scikit-learn でモジュールが用意されているものになります。\n",
    "\n",
    "今回スコープからは調査を除外しますが、興味ついでに・・・後日検討の比較ねたとして記載しておきます。\n",
    "\n",
    "なんとなくですが、意味解析にはこちらの方が使えるのではないか？　などという感触を今のところは得ています。\n",
    "\n",
    "（どうやってやるのか？　はこれも後日検討でしょうか）\n",
    "\n",
    "- PCA（Principal Component Analysis）\n",
    "\n",
    " 教師なしのデータを次元削除する方法として、という方法が知られているようです。\n",
    " \n",
    " PCAとLDAの比較例についてはこちら：\n",
    " \n",
    " 　http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-lda-py\n",
    "\n",
    " 概して精度は低いようです。\n",
    "\n",
    "\n",
    "- クラスタリング\n",
    "\n",
    " ラベル付けがなされていないデータに対して、近い属性を持つデータをグループ化する手法です。\n",
    "\n",
    " K-Means という方法が知られているようです。\n",
    " \n",
    " データを大量投入して、一括計算（学習）する性質のものなので、運用イメージとしては日次または週次バッチかと思われます。\n",
    " \n",
    " （もちろん予測処理じたいはオンライン／リアルタイムでできるのでしょうが）\n",
    " \n",
    " また、出力されたクラスタの分類が「どういう意味なのか」を知るには、人手のレビューが必要になってしまうかと存じます。\n",
    "\n",
    " （あらかじめ決めておいたカテゴリーのどれに属するのかを当てはめていく、という予測アプローチではないため）\n",
    " \n",
    " \n",
    "- Decision Tree\n",
    "\n",
    " 教師ありき学習の方法として、決定木分析というのがあるようです。\n",
    "\n",
    " 属性・属性値ペア（PythonのDictイメージ？）のリストとして与えられるデータを受取り、それをあらかじめ決めておいたカテゴリのどれに属すかを決定するもののようです。\n",
    "\n",
    " 属性＝分岐点（ノード）Excel の列見出しみたいなもの\n",
    "\n",
    " 属性値＝分岐（テスト項目）すなわち属性値の数＝分岐の数になります。Excelでいうとセルのなかみ\n",
    "\n",
    " カテゴリー＝葉っぱの部分。すなわち決定木のアウトプットになります\n",
    " \n",
    " これも木を作る（＝学習）のはバッチ、予測を行うのはオンライン・・・といったイメージになるのでしょうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
