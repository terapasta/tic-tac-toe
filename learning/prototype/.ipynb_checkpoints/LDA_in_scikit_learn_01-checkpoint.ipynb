{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LDAの動作確認 part 2\n",
    "\n",
    "LDA_in_scikit_learn_00 での動作確認結果が、いまひとつ理解できなかったため、公式ドキュメントを確認しコメントを入れながら、再度調査してみました。\n",
    "\n",
    "公式ドキュメント：\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "結論から申し上げると、\n",
    "\n",
    "(1) 使用した以下のサンプル（公式ドキュメントのサンプル）は、辞書なし学習の例でした。\n",
    "\n",
    "(2) LatentDirichletAllocation というモジュールの仕様上、学習実行--->即結果が出力される・・・といった使い勝手のようです。\n",
    "\n",
    "このレポートでは、公式ドキュメントから読み取れる仕様にもとづき、正しいと思われる使い方で再試行してみました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## テスト用データ（2,000行）のロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 1.607s.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, \n",
    "                             random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "n_samples = 2000\n",
    "test_data = dataset.data[:n_samples]\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## コーパスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.316s.\n"
     ]
    }
   ],
   "source": [
    "n_features = 1000\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95,\n",
    "                                min_df=3,\n",
    "                                max_features=n_features, # 特徴語の上限\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(test_data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2,000 件のサンプルテキストから、51,754 件の単語が抽出され、戻り値の tf に単語の出現回数がセットされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51754"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 2, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "len(tf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 2.415s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=10, # １０のトピックに分類\n",
    "                                max_iter=5, # ５回繰り返し実行\n",
    "                                learning_method='online', # 学習実行-->即結果を出力\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "answers = lda.fit_transform(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 学習結果\n",
    "\n",
    "１０のトピックに含まれる上位１０件の特徴語をリストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "section,armenians,armenian,turkish,military,firearm,weapon,dangerous,azerbaijan,license\n",
      "Topic #1:\n",
      "god,people,does,jesus,bible,church,law,christian,religion,believe\n",
      "Topic #2:\n",
      "edu,mail,windows,com,file,send,graphics,version,thanks,ftp\n",
      "Topic #3:\n",
      "game,11,10,team,play,18,flyers,period,23,19\n",
      "Topic #4:\n",
      "bike,rules,luck,ve,court,safety,good,exist,questions,van\n",
      "Topic #5:\n",
      "just,people,don,like,think,know,time,good,way,make\n",
      "Topic #6:\n",
      "drive,disk,hard,car,drives,card,scsi,speed,controller,rom\n",
      "Topic #7:\n",
      "space,earth,surface,moon,probe,data,science,lunar,nasa,orbit\n",
      "Topic #8:\n",
      "key,government,chip,use,public,encryption,clipper,keys,security,private\n",
      "Topic #9:\n",
      "55,10,new,00,1993,hiv,health,april,500,15\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "top_words = []\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    top_words_idx = topic.argsort()[:(-n_top_words - 1):-1]\n",
    "    top_words_list = [tf_feature_names[i] for i in top_words_idx]\n",
    "    top_words.append(top_words_list)\n",
    "    print(\",\".join(top_words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "トピックの分類結果を表示します。\n",
    "\n",
    "試しに、テストデータ #557 で見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01000015,  0.01000039,  0.27071617,  0.0100013 ,  0.01000049,\n",
       "        0.0100005 ,  0.64927728,  0.01000018,  0.01000099,  0.01000255])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[557]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "７番目のトピック #6 との回答です。テストデータの内容と突合すると、当たっているようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Topic #6:\n",
      "drive,disk,hard,car,drives,card,scsi,speed,controller,rom\n",
      "==========\n",
      "Sample Text:\n",
      "Is there a QIC-80 format tape drive that comes\n",
      "with an EISA controller ?\n",
      "Colorado's 250 only has ISA and MCA controllers.\n",
      "\n",
      "Thanks. e-mail please.\n",
      "\n",
      "-- \n"
     ]
    }
   ],
   "source": [
    "print(\"==========\")\n",
    "print(\"Topic #6:\")\n",
    "print(\",\".join(top_words[6]))\n",
    "print(\"==========\")\n",
    "print(\"Sample Text:\")\n",
    "print(test_data[557])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
