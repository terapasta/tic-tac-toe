{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LDAの動作確認 part 2\n",
    "\n",
    "LDA_in_scikit_learn_00 での動作確認結果が、いまひとつ理解できなかったため、公式ドキュメントを確認しコメントを入れながら、再度調査してみました。\n",
    "\n",
    "公式ドキュメント：\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "結論から申し上げると、\n",
    "\n",
    "(1) 使用した以下のサンプル（公式ドキュメントのサンプル）は、辞書なし学習の例でした。\n",
    "\n",
    "(2) LatentDirichletAllocation というモジュールの仕様上、学習実行--->即結果が出力される・・・といった使い勝手のようです。\n",
    "\n",
    "このレポートでは、公式ドキュメントから読み取れる仕様にもとづき、正しいと思われる使い方で再試行してみました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## テスト用データ（2,000行）のロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 1.674s.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, \n",
    "                             random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "test_data = dataset.data[:2000]\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## コーパスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.319s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95,\n",
    "                                min_df=3,\n",
    "                                max_features=1000, # 特徴語の上限\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(test_data)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2,000 件のサンプルテキストから、51,754 件の単語が抽出され、戻り値の tf に単語の出現回数がセットされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51754"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 2, 1, 1, 1,\n",
       "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "len(tf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 学習実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=1000 and n_features=500...\n",
      "done in 8.014s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=10, # １０のトピックに分類\n",
    "                                max_iter=20, # ２０回繰り返し実行\n",
    "                                learning_method='online', # 学習実行-->即結果を出力\n",
    "                                learning_offset=50.,\n",
    "                                random_state=1)\n",
    "t0 = time()\n",
    "answers = lda.fit_transform(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 学習結果\n",
    "\n",
    "１０のトピックに含まれる上位１０件の特徴語をリストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "edu,com,mail,send,ftp,graphics,pub,message,contact,faq\n",
      "Topic #1:\n",
      "10,55,11,space,team,12,15,18,game,20\n",
      "Topic #2:\n",
      "god,jesus,bible,church,people,christian,does,hiv,faith,christ\n",
      "Topic #3:\n",
      "law,section,weapons,gun,military,weapon,shall,firearm,person,dangerous\n",
      "Topic #4:\n",
      "drive,disk,hard,drives,scsi,controller,card,rom,bios,16\n",
      "Topic #5:\n",
      "car,key,government,000,chip,people,encryption,year,new,clipper\n",
      "Topic #6:\n",
      "bike,cubs,win,dog,runs,games,game,ground,division,head\n",
      "Topic #7:\n",
      "israel,jews,jewish,women,men,attacks,world,war,israeli,price\n",
      "Topic #8:\n",
      "use,windows,thanks,program,using,software,new,version,pc,computer\n",
      "Topic #9:\n",
      "just,don,people,like,think,know,good,time,way,say\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "top_words = []\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    top_words_idx = topic.argsort()[:(-n_top_words - 1):-1]\n",
    "    top_words_list = [tf_feature_names[i] for i in top_words_idx]\n",
    "    top_words.append(top_words_list)\n",
    "    print(\",\".join(top_words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "トピックの分類結果を表示します。\n",
    "\n",
    "試しに、テストデータ #557 で見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01000431,  0.01000377,  0.01000074,  0.01000024,  0.25526706,\n",
       "        0.01000225,  0.01000087,  0.01000154,  0.66471858,  0.01000063])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[557]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "９番目のトピック #8 との回答です。テストデータの内容と突合すると、当たっているようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Topic #8:\n",
      "use,windows,thanks,program,using,software,new,version,pc,computer\n",
      "==========\n",
      "Sample Text:\n",
      "Is there a QIC-80 format tape drive that comes\n",
      "with an EISA controller ?\n",
      "Colorado's 250 only has ISA and MCA controllers.\n",
      "\n",
      "Thanks. e-mail please.\n",
      "\n",
      "-- \n"
     ]
    }
   ],
   "source": [
    "print(\"==========\")\n",
    "print(\"Topic #8:\")\n",
    "print(\",\".join(top_words[8]))\n",
    "print(\"==========\")\n",
    "print(\"Sample Text:\")\n",
    "print(data_samples[557])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
