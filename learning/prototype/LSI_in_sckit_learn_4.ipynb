{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSIによる次元圧縮の動作確認\n",
    "\n",
    "ストーリー: https://www.pivotaltracker.com/story/show/149341617\n",
    "\n",
    "LSI_in_sckit_learn_3.ipynbの続きで、ボキャブラリーのall.csvを追加することでどのように結果が変わるか実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shwld/project/mofmof/donusagi-bot/learning/prototype'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_dir = os.path.abspath(\"../\")\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from learning.core.nlang import Nlang\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [追加処理] ボキャブラリーの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('prototype/fixtures/learning_training_messages/all.csv')\n",
    "all_sentences = np.array(all_df['question'])\n",
    "all_separated_sentences = Nlang.batch_split(all_sentences)\n",
    "all_separated_sentences\n",
    "vectorizer = TfidfVectorizer(use_idf=True, token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "all_features = vectorizer.fit_transform(all_separated_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['育児 短時間 勤務 申請 書 いつ 提出 する',\n",
       " '育児 短時間 勤務 申請 書 曜日 別 申請 できる',\n",
       " '育児 短時間 勤務 申請 どこ 提出 する よい',\n",
       " '子供 生まれる',\n",
       " 'ＶＩＳＡ 勘定 科目 わかる ない',\n",
       " '海外 出張 する 旅費 精算 する どう する 良い',\n",
       " '保険証 失 くい']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./prototype/fixtures/learning_training_messages/LSI_in_sckit_learn.csv')\n",
    "sentences = np.array(df['question'])\n",
    "separated_sentences = Nlang.batch_split(sentences)\n",
    "separated_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizerを用いてベクトルを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = vectorizer.transform(separated_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検索する単語も同様に処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['こども うまれる']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['うまれる 赤ちゃん 抱く']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences = np.array(['こどもがうまれた'])\n",
    "target_separated_sentences = Nlang.batch_split(target_sentences)\n",
    "target_features = vectorizer.transform(target_separated_sentences)\n",
    "print(target_separated_sentences)\n",
    "target_sentences2 = np.array(['うまれたばかりの赤ちゃんを抱いた'])\n",
    "target_separated_sentences2 = Nlang.batch_split(target_sentences2)\n",
    "target_features2 = vectorizer.transform(target_separated_sentences2)\n",
    "target_separated_sentences2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コサイン類似検索をかけてみる(LSIなし)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, '育児 短時間 勤務 申請 書 いつ 提出 する', '育児短時間勤務申請書はいつまでに提出するのか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 書 曜日 別 申請 できる', '育児短時間勤務申請書は曜日別に申請できるか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 どこ 提出 する よい', '育児短時間勤務申請はどこへ提出すればよいか？'),\n",
       " (0.0, '子供 生まれる', '子供が生まれた'),\n",
       " (0.0, 'ＶＩＳＡ 勘定 科目 わかる ない', 'VISAの勘定科目がわからない'),\n",
       " (0.0, '海外 出張 する 旅費 精算 する どう する 良い', '海外出張したときの旅費精算をしたいがどうしたら良い'),\n",
       " (0.0, '保険証 失 くい', '保険証を失くした')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = cosine_similarity(features, target_features)\n",
    "similarities = similarities.flatten()\n",
    "zipped_data = zip(similarities, separated_sentences, np.array(df['question']))\n",
    "list(sorted(zipped_data, key=lambda x: x[0], reverse=True))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, '育児 短時間 勤務 申請 書 いつ 提出 する', '育児短時間勤務申請書はいつまでに提出するのか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 書 曜日 別 申請 できる', '育児短時間勤務申請書は曜日別に申請できるか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 どこ 提出 する よい', '育児短時間勤務申請はどこへ提出すればよいか？'),\n",
       " (0.0, '子供 生まれる', '子供が生まれた'),\n",
       " (0.0, 'ＶＩＳＡ 勘定 科目 わかる ない', 'VISAの勘定科目がわからない'),\n",
       " (0.0, '海外 出張 する 旅費 精算 する どう する 良い', '海外出張したときの旅費精算をしたいがどうしたら良い'),\n",
       " (0.0, '保険証 失 くい', '保険証を失くした')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = cosine_similarity(features, target_features2)\n",
    "similarities = similarities.flatten()\n",
    "zipped_data = zip(similarities, separated_sentences, np.array(df['question']))\n",
    "list(sorted(zipped_data, key=lambda x: x[0], reverse=True))[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruncatedSVDで次元圧縮する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=6, algorithm='randomized', n_iter=10, random_state=42)\n",
    "lsa.fit(all_features)\n",
    "lsa_features = lsa.transform(features)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa_features = normalizer.fit_transform(lsa_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsa_target_features = lsa.transform(target_features)\n",
    "lsa_target_features = normalizer.transform(lsa_target_features)\n",
    "lsa_target_features2 = lsa.transform(target_features2)\n",
    "lsa_target_features2 = normalizer.transform(lsa_target_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2945)\n",
      "(1, 2945)\n",
      "(1, 2945)\n",
      "(7, 6)\n",
      "(1, 6)\n",
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "# LSI無し\n",
    "print(features.shape)\n",
    "print(target_features.shape)\n",
    "print(target_features2.shape)\n",
    "\n",
    "# LSIあり\n",
    "print(lsa_features.shape)\n",
    "print(lsa_target_features.shape)\n",
    "print(lsa_target_features2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コサイン類似検索をかけてみる(LSIあり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, '育児 短時間 勤務 申請 書 いつ 提出 する', '育児短時間勤務申請書はいつまでに提出するのか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 書 曜日 別 申請 できる', '育児短時間勤務申請書は曜日別に申請できるか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 どこ 提出 する よい', '育児短時間勤務申請はどこへ提出すればよいか？'),\n",
       " (0.0, '子供 生まれる', '子供が生まれた'),\n",
       " (0.0, 'ＶＩＳＡ 勘定 科目 わかる ない', 'VISAの勘定科目がわからない'),\n",
       " (0.0, '海外 出張 する 旅費 精算 する どう する 良い', '海外出張したときの旅費精算をしたいがどうしたら良い'),\n",
       " (0.0, '保険証 失 くい', '保険証を失くした')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_similarities = cosine_similarity(lsa_features, lsa_target_features)\n",
    "lsa_similarities = lsa_similarities.flatten()\n",
    "zipped_data = zip(lsa_similarities, separated_sentences, np.array(df['question']))\n",
    "list(sorted(zipped_data, key=lambda x: x[0], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, '育児 短時間 勤務 申請 書 いつ 提出 する', '育児短時間勤務申請書はいつまでに提出するのか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 書 曜日 別 申請 できる', '育児短時間勤務申請書は曜日別に申請できるか？'),\n",
       " (0.0, '育児 短時間 勤務 申請 どこ 提出 する よい', '育児短時間勤務申請はどこへ提出すればよいか？'),\n",
       " (0.0, '子供 生まれる', '子供が生まれた'),\n",
       " (0.0, 'ＶＩＳＡ 勘定 科目 わかる ない', 'VISAの勘定科目がわからない'),\n",
       " (0.0, '海外 出張 する 旅費 精算 する どう する 良い', '海外出張したときの旅費精算をしたいがどうしたら良い'),\n",
       " (0.0, '保険証 失 くい', '保険証を失くした')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_similarities = cosine_similarity(lsa_features, lsa_target_features2)\n",
    "lsa_similarities = lsa_similarities.flatten()\n",
    "zipped_data = zip(lsa_similarities, separated_sentences, np.array(df['question']))\n",
    "list(sorted(zipped_data, key=lambda x: x[0], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDAも試してみる\n",
    "\n",
    "試せそうだったので `LDA_in_scikit_learn_xx.ipynb` あたりを参考にLDAを試して比較してみた。\n",
    "\n",
    "http://hivecolor.com/id/65\n",
    "\n",
    "によると、\n",
    "\n",
    "> LSIもLDAも、次元をトピック単位に縮約するのは同じでした。lsiコーパスとldaコーパスの値もほとんど同じです。ただ、全く同じではなく、LSIとLDAには、「確率的な揺らぎを考慮するかどうか」という違いがあります。\n",
    "\n",
    "> LSIでは、一緒に使われている単語であれば、そのうち片方の単語で検索すると、もう片方の単語の結果も見付かることをちょっと前に書きました。しかしながら、どれだけ意味が似ている単語であっても、一緒に使われていなければそういう検索はできないという弱点があります。\n",
    "\n",
    "> LDAでは、LSIに確率分布を取り入れることで、直接的には一緒に使われていない単語同士であっても検索で見付けることができるようになります。\n",
    "\n",
    "> これまた詳しくないので詳細な説明はできないのですが、利用者の立場としては、LSIの発展版がLDAだ、くらいに思っておけばいいんじゃないかと思います。\n",
    "\n",
    "のように書いてあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=8, \n",
    "                                max_iter=5,\n",
    "                                learning_method='online')\n",
    "\n",
    "lda.fit(all_features)\n",
    "lda_features = lda.transform(features)\n",
    "lda_features = normalizer.fit_transform(lda_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_target_features = lda.transform(target_features)\n",
    "lda_target_features = normalizer.transform(lda_target_features)\n",
    "lda_target_features2 = lda.transform(target_features2)\n",
    "lda_target_features2 = normalizer.transform(lda_target_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2945)\n",
      "(1, 2945)\n",
      "(1, 2945)\n",
      "(7, 8)\n",
      "(1, 8)\n",
      "(1, 8)\n"
     ]
    }
   ],
   "source": [
    "# LDA無し\n",
    "print(features.shape)\n",
    "print(target_features.shape)\n",
    "print(target_features2.shape)\n",
    "\n",
    "# LDAあり\n",
    "print(lda_features.shape)\n",
    "print(lda_target_features.shape)\n",
    "print(lda_target_features2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コサイン類似検索をかけてみる(LDAあり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.70141489349102015, '保険証 失 くい', '保険証を失くした'),\n",
       " (0.65582999615287074,\n",
       "  '海外 出張 する 旅費 精算 する どう する 良い',\n",
       "  '海外出張したときの旅費精算をしたいがどうしたら良い'),\n",
       " (0.64529013998095408, '育児 短時間 勤務 申請 書 曜日 別 申請 できる', '育児短時間勤務申請書は曜日別に申請できるか？'),\n",
       " (0.64441446184776363, 'ＶＩＳＡ 勘定 科目 わかる ない', 'VISAの勘定科目がわからない'),\n",
       " (0.57396131054704169, '育児 短時間 勤務 申請 どこ 提出 する よい', '育児短時間勤務申請はどこへ提出すればよいか？'),\n",
       " (0.54255708967841776, '子供 生まれる', '子供が生まれた'),\n",
       " (0.45921902111447244, '育児 短時間 勤務 申請 書 いつ 提出 する', '育児短時間勤務申請書はいつまでに提出するのか？')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_similarities = cosine_similarity(lda_features, lda_target_features)\n",
    "lda_similarities = lda_similarities.flatten()\n",
    "zipped_data = zip(lda_similarities, separated_sentences, np.array(df['question']))\n",
    "list(sorted(zipped_data, key=lambda x: x[0], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コサイン類似検索をかけてみる(LDAあり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.70141489349102015, '保険証 失 くい', '保険証を失くした'),\n",
       " (0.65582999615287074,\n",
       "  '海外 出張 する 旅費 精算 する どう する 良い',\n",
       "  '海外出張したときの旅費精算をしたいがどうしたら良い'),\n",
       " (0.64529013998095408, '育児 短時間 勤務 申請 書 曜日 別 申請 できる', '育児短時間勤務申請書は曜日別に申請できるか？'),\n",
       " (0.64441446184776363, 'ＶＩＳＡ 勘定 科目 わかる ない', 'VISAの勘定科目がわからない'),\n",
       " (0.57396131054704169, '育児 短時間 勤務 申請 どこ 提出 する よい', '育児短時間勤務申請はどこへ提出すればよいか？'),\n",
       " (0.54255708967841776, '子供 生まれる', '子供が生まれた'),\n",
       " (0.45921902111447244, '育児 短時間 勤務 申請 書 いつ 提出 する', '育児短時間勤務申請書はいつまでに提出するのか？')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_similarities = cosine_similarity(lda_features, lda_target_features2)\n",
    "lda_similarities = lda_similarities.flatten()\n",
    "zipped_data = zip(lda_similarities, separated_sentences, np.array(df['question']))\n",
    "list(sorted(zipped_data, key=lambda x: x[0], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータ調整\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n",
    "を参考にパラメータを調整してみた。\n",
    "\n",
    "何か間違っているのかもしれないが、色々調整してみても、上記のように全く予測できていない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ボキャブラリーの影響調査についての結果\n",
    "\n",
    "- ボキャブラリーが増え、余計な単語が増えてしまったことにより既存のままだと精度が低くなってしまった?\n",
    "- LSIを使っている場合は、次元削減により一定に削減されるため精度が低くなることはなかった。\n",
    "- ボキャブラリーが増えたことによりLSIで関連性の有りそうな質問が見つかるようになった。 <- 重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LSIについての調査結果\n",
    "\n",
    "\n",
    "TF-IDFによって単語の重み(出現頻度)がわかるが、SVDで次元圧縮することにより、Questionの他の単語とどのくらい関連があるかを見て近い意味の単語を近いベクトルとして計算できる。\n",
    "マイオペの場合、検索語も検索対象も単語数が少ないことが多いため、関連がある(一緒に使われている)かどうかでの検索での改善が若干難しそう。\n",
    "-> 「こんにちは」、「こんにちわ」が一致してくれないのはどちらも1単語だからだと思われる。\n",
    "\n",
    "質問するときは少なくとも、1単語プラス動詞とかでやったほうが改善する。\n",
    "\n",
    "LSIを利用しないままだと、おそらく質問が増えるほどにsimilalityが落ちていくと思われるので、LSIを入れておいたほうが良さそう。\n",
    "\n",
    "一般的な単語と、それを使った質問例文がボキャブラリーとしてfitできると、ひらがな・カタカナの違いなどは改善しそう。\n",
    "\n",
    "\n",
    "\n",
    "調査時に参考にしたページ\n",
    "\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html\n",
    "http://elsur.jpn.org/reading_notes/Greenacre1984.pdf\n",
    "http://qiita.com/yuku_t/items/483b56be83a3a5423b09\n",
    "https://ja.wikipedia.org/wiki/%E7%89%B9%E7%95%B0%E5%80%A4%E5%88%86%E8%A7%A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
