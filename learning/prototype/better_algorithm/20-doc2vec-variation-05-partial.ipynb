{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Doc2Vecの動作確認（bot_id=11）\n",
    "\n",
    "\n",
    "実行条件は下記の通りとします。\n",
    "\n",
    "- すべての教師データのタグをユニークにするため、[ラベル]\\_[連番] 形式のタグを付与\n",
    "\n",
    "\n",
    "- 一部品詞を落す（Nlangクラスの仕様に従う）\n",
    "\n",
    "\n",
    "- DBOWを使用\n",
    "\n",
    "\n",
    "- feature数は、実質的な教師データのパターン数と整合させる（ユーザーさんによっては、回答ラベル数が必ずしも回答パターン数と合致しないため、ラベル数の２倍程度の値を設定するのを目安とします）\n",
    "\n",
    "\n",
    "- 学習時の反復回数を [feature数 * 10] に設定\n",
    "\n",
    "\n",
    "現在テストデータとして用意されているBot（ID=11：benefitone.csv）で動作確認を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) テストデータ／環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    テスト環境を準備するためのモジュールを使用します。\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) 学習／予測処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-1) コーパス生成\n",
    "\n",
    "コーパス（単語が半角スペースで区切られた文字列）生成時、一部の品詞を落とすようにします。\n",
    "\n",
    "（＝learning.core.nlang.Nlang クラスの仕様に従います）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from learning.core.learn.learning_parameter import LearningParameter\n",
    "from learning.core.datasource import Datasource\n",
    "\n",
    "_bot_id = 11\n",
    "attr = {\n",
    "    'include_failed_data': False,\n",
    "    'include_tag_vector': False,\n",
    "    'classify_threshold': 0.5,\n",
    "    'algorithm': LearningParameter.ALGORITHM_LOGISTIC_REGRESSION,\n",
    "    'params_for_algorithm': {'C': 140},\n",
    "    'excluded_labels_for_fitting': None\n",
    "}\n",
    "\n",
    "learning_parameter = LearningParameter(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/22 AM 12:04:59 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/22 AM 12:04:59 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    }
   ],
   "source": [
    "_datasource = Datasource(type='csv')\n",
    "learning_training_messages = _datasource.learning_training_messages(_bot_id)\n",
    "questions = np.array(learning_training_messages['question'])\n",
    "answer_ids = np.array(learning_training_messages['answer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from learning.core.nlang import Nlang\n",
    "\n",
    "_sentences = np.array(questions)\n",
    "_separated_sentences = Nlang.batch_split(_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-2) タグ付け\n",
    "\n",
    "ラベル毎の教師データ数を制限した学習セットを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "class Doc2VecTrainingSet:\n",
    "    def __init__(self):\n",
    "        self.answer_id_count = {}\n",
    "        self.selected_answer_ids = []\n",
    "        self.selected_questions = []\n",
    "        self.selected_separated_sentences = []\n",
    "\n",
    "    def build(self, questions, answer_ids, separated_sentences):\n",
    "        for index, answer_id in enumerate(answer_ids):\n",
    "            if answer_id not in self.answer_id_count.keys():\n",
    "                self.answer_id_count[answer_id] = 0\n",
    "\n",
    "            '''\n",
    "                データをリストに格納\n",
    "                ラベルはユニークにする必要があるので、\n",
    "                [answer_id]_[連番] の形式で編集\n",
    "            '''\n",
    "            self.selected_answer_ids.append('%04d_%02d' % (\n",
    "                answer_id,\n",
    "                self.answer_id_count[answer_id]\n",
    "            ))\n",
    "            self.selected_questions.append(questions[index])\n",
    "            self.selected_separated_sentences.append(separated_sentences[index])\n",
    "            self.answer_id_count[answer_id] += 1\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_tagged_document_list(self):\n",
    "        '''\n",
    "            ユニークになったコーパス／ラベルから、\n",
    "            学習セットを生成する\n",
    "        '''\n",
    "        tagged_document_list = self.__corpus_to_sentences(\n",
    "            self.selected_separated_sentences, \n",
    "            self.selected_answer_ids\n",
    "        )\n",
    "\n",
    "        return tagged_document_list\n",
    "\n",
    "    def __get_tagged_document(self, sentences, name):\n",
    "        '''\n",
    "            models.doc2vecの仕様に従い\n",
    "            コーパスにタグ付け\n",
    "        '''\n",
    "        words = sentences.split(' ')\n",
    "        return TaggedDocument(words=words, tags=[name])\n",
    "\n",
    "    def __corpus_to_sentences(self, separated_sentences, answer_ids):\n",
    "        '''\n",
    "            TaggedDocumentを生成し、リストに格納\n",
    "        '''\n",
    "        tagged_document_list = []\n",
    "        for idx, (doc, name) in enumerate(zip(separated_sentences, answer_ids)):\n",
    "            tagged_document = self.__get_tagged_document(doc, name)\n",
    "            tagged_document_list.append(tagged_document)\n",
    "            \n",
    "        return tagged_document_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Doc2VecTrainingSet at 0x108ad2ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    ユニークになったコーパス／ラベルから、\n",
    "    学習セットを生成する\n",
    "    \n",
    "    ラベル数＝88、サンプル数＝7,083\n",
    "'''\n",
    "d2v_training_set = Doc2VecTrainingSet()\n",
    "d2v_training_set.build(questions, answer_ids, _separated_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-3) 学習処理／モデルのシリアライズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def doc2vec_model_path(bot_id):\n",
    "    model_path = 'prototype/better_algorithm/doc2vec.bot%02d.model' % bot_id\n",
    "\n",
    "    return model_path\n",
    "\n",
    "def train_by_doc2vec(bot_id, doc2vec_training_set):\n",
    "    '''\n",
    "        パラメータ：\n",
    "         学習時にDBOWを使用する\n",
    "         featureの数を回答パターン数の２倍（仮決め）に設定\n",
    "         反復回数をfeature数の10倍に設定\n",
    "    '''\n",
    "    sentence_list = doc2vec_training_set.get_tagged_document_list()\n",
    "    n_pattern = len(doc2vec_training_set.answer_id_count)\n",
    "    print('train_by_doc2vec: Train data sample=%d, Train data pattern=%d' % (len(sentence_list), n_pattern))\n",
    "\n",
    "    n_feature = n_pattern * 2\n",
    "    n_iter = n_feature * 10\n",
    "    print('train_by_doc2vec: Feature size=%d, Max iteration count=%d' % (n_feature, n_iter))\n",
    "\n",
    "    # ボキャブラリ生成／学習実行\n",
    "    model = Doc2Vec(dm=0, size=n_feature, min_count=1, iter=n_iter)\n",
    "    model.build_vocab(sentence_list)\n",
    "    ret = model.train(sentence_list)\n",
    "\n",
    "    '''\n",
    "        モデル内に保持されているベクトルの数を取得\n",
    "        （featureの数 [回答パターン数の２倍] と同じであることを確認）\n",
    "    '''\n",
    "    if len(model.docvecs) != len(sentence_list):\n",
    "        raise Exception('train_by_doc2vec: Failed to create document vector')\n",
    "\n",
    "    # 学習モデルは、ファイルに保存しておく\n",
    "    model.save(doc2vec_model_path(bot_id))\n",
    "    print('train_by_doc2vec: document vector size=%d, return=%d' % (len(model.docvecs), ret))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_by_doc2vec: Train data sample=7083, Train data pattern=88\n",
      "train_by_doc2vec: Feature size=176, Max iteration count=1760\n",
      "train_by_doc2vec: document vector size=7083, return=45088851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45088851"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    生成された学習セット（タグ付きドキュメント）を\n",
    "    使用し、学習実行\n",
    "'''\n",
    "train_by_doc2vec(_bot_id, d2v_training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) accuracy 測定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_similarity(separated_sentence):\n",
    "    corpus = separated_sentence.split()\n",
    "    inferred_vector = loaded_model.infer_vector(corpus)\n",
    "    ret = loaded_model.docvecs.most_similar([inferred_vector])\n",
    "\n",
    "    answer_id, similarity = ret[0]\n",
    "    return corpus, answer_id, similarity\n",
    "\n",
    "def get_prediction_statistics(separated_sentences, answer_ids):\n",
    "    '''\n",
    "        学習セットの質問文をそのまま予測処理にかけて、\n",
    "        回答を予測\n",
    "    '''\n",
    "    statistics = []\n",
    "    for i, _ in enumerate(separated_sentences):\n",
    "        sentence = separated_sentences[i]\n",
    "        preferred_answer_id = answer_ids[i]\n",
    "        corpus, answer_id, similarity = predict_similarity(separated_sentences[i])\n",
    "        corpus_len = len(corpus)\n",
    "        statistics.append((i, corpus_len, preferred_answer_id, answer_id, similarity))\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(prediction_statistics):\n",
    "    '''\n",
    "        予測結果を、質問文の単語数毎／回答ID毎に統計する\n",
    "    '''\n",
    "    ncorrect_by_corpus_len = {}\n",
    "    nsample_by_corpus_len = {}\n",
    "\n",
    "    ncorrect = 0\n",
    "    nsample = 0\n",
    "\n",
    "    for statistics in prediction_statistics:\n",
    "        i, corpus_len, preferred_answer_id, answer_id, similarity = statistics\n",
    "\n",
    "        '''\n",
    "            質問文の単語数ごとに統計を取る\n",
    "        '''\n",
    "        if corpus_len not in nsample_by_corpus_len.keys():\n",
    "            ncorrect_by_corpus_len[corpus_len] = 0\n",
    "            nsample_by_corpus_len[corpus_len] = 0\n",
    "        nsample_by_corpus_len[corpus_len] += 1\n",
    "\n",
    "        '''\n",
    "            正解かどうか検査\n",
    "            （NNNN_nn 形式ラベルの上４桁が一致していれば正解とします）\n",
    "        '''\n",
    "        nsample += 1\n",
    "        if preferred_answer_id[0:4] == answer_id[0:4]:\n",
    "            ncorrect += 1\n",
    "            ncorrect_by_corpus_len[corpus_len] += 1\n",
    "    \n",
    "    '''\n",
    "        全体の正解率\n",
    "    '''\n",
    "    accuracy = ncorrect / nsample\n",
    "    print(\"accuracy=%0.3f (%d/%d)\" % (accuracy, ncorrect, nsample))\n",
    "\n",
    "    '''\n",
    "        質問文の単語数ごとの統計情報を編集\n",
    "    '''\n",
    "    info_by_corpus_len = []\n",
    "    for k, v in ncorrect_by_corpus_len.items():\n",
    "        info_by_corpus_len.append((\n",
    "            k, \n",
    "            ncorrect_by_corpus_len[k]/nsample_by_corpus_len[k], \n",
    "            ncorrect_by_corpus_len[k], \n",
    "            nsample_by_corpus_len[k]\n",
    "        ))\n",
    "\n",
    "    '''\n",
    "        質問文の単語数ごとの正解率をリスト\n",
    "    '''\n",
    "    print(\"Accuracy info by word count...\")\n",
    "    for info in info_by_corpus_len:\n",
    "        print(\"word_count=%2d: accuracy=%0.3f (%d/%d)\" % (\n",
    "            info[0], info[1], info[2], info[3]\n",
    "        ))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = models.Doc2Vec.load(doc2vec_model_path(_bot_id))\n",
    "\n",
    "selected_separated_sentences = d2v_training_set.selected_separated_sentences\n",
    "selected_answer_ids = d2v_training_set.selected_answer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.946 (6703/7083)\n",
      "Accuracy info by word count...\n",
      "word_count= 1: accuracy=0.953 (162/170)\n",
      "word_count= 2: accuracy=0.944 (1417/1501)\n",
      "word_count= 3: accuracy=0.935 (2257/2415)\n",
      "word_count= 4: accuracy=0.943 (1590/1687)\n",
      "word_count= 5: accuracy=0.973 (728/748)\n",
      "word_count= 6: accuracy=0.971 (336/346)\n",
      "word_count= 7: accuracy=0.979 (137/140)\n",
      "word_count= 8: accuracy=1.000 (60/60)\n",
      "word_count= 9: accuracy=1.000 (8/8)\n",
      "word_count=10: accuracy=1.000 (6/6)\n",
      "word_count=11: accuracy=1.000 (2/2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9463504164901878"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_statistics = get_prediction_statistics(selected_separated_sentences, selected_answer_ids)\n",
    "calculate_accuracy(prediction_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (4) 予測処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(word, bot_id):\n",
    "    '''\n",
    "        予測処理にかけるコーパスを生成\n",
    "        （学習セット作成時と同じ関数を使用）\n",
    "    '''\n",
    "    corpus = Nlang.split(word).split()\n",
    "\n",
    "    '''\n",
    "        コーパスからベクトルを生成し、\n",
    "        ロードしたモデルから類似ベクトルを検索\n",
    "    '''\n",
    "    loaded_model = models.Doc2Vec.load(doc2vec_model_path(bot_id))\n",
    "    inferred_vector = loaded_model.infer_vector(corpus)\n",
    "    ret = loaded_model.docvecs.most_similar([inferred_vector])\n",
    "\n",
    "    return corpus, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-1) nosetestsにあった質問文\n",
    "\n",
    "正しく回答することができているようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['契約', '書', '見る'],\n",
       " [('4683_12', 0.8393585681915283),\n",
       "  ('4683_25', 0.8343852758407593),\n",
       "  ('4683_24', 0.8337586522102356),\n",
       "  ('4683_00', 0.8298937082290649),\n",
       "  ('4683_09', 0.7951401472091675),\n",
       "  ('4683_21', 0.7864588499069214),\n",
       "  ('4683_13', 0.702258288860321),\n",
       "  ('4683_15', 0.7021685242652893),\n",
       "  ('4683_23', 0.7002915143966675),\n",
       "  ('4683_01', 0.6947280168533325)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    契約書を見たいのですが（正解＝4683）\n",
    "'''\n",
    "predict('契約書を見たいのですが', _bot_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ＥＸ', 'カード', '貸す'],\n",
       " [('4678_692', 0.797877311706543),\n",
       "  ('4678_2700', 0.7967407703399658),\n",
       "  ('4678_2694', 0.7926852703094482),\n",
       "  ('4678_686', 0.7879177927970886),\n",
       "  ('4678_2213', 0.685415506362915),\n",
       "  ('4678_4221', 0.6775147318840027),\n",
       "  ('4678_2695', 0.6713133454322815),\n",
       "  ('4678_687', 0.6649485230445862),\n",
       "  ('4678_2698', 0.652132511138916),\n",
       "  ('4678_694', 0.649863600730896)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    EXカードを貸してください（正解＝4678）\n",
    "'''\n",
    "predict('EXカードを貸してください', _bot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-2) 教師データに存在する、単語１語だけの質問文\n",
    "\n",
    "三脚が含まれる質問文が候補としてリストされます。類似度が0.5を上回る結果となります。\n",
    "\n",
    "（ちなみに確認したところ、4740と4741は同じ「三脚を借りたいのですね。総務部に・・・」という回答文でした）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['三脚'],\n",
       " [('4740_01', 0.7236194610595703),\n",
       "  ('4740_13', 0.7219536900520325),\n",
       "  ('4740_00', 0.7217124104499817),\n",
       "  ('4740_16', 0.7133685350418091),\n",
       "  ('4740_19', 0.712550163269043),\n",
       "  ('4740_07', 0.7086933851242065),\n",
       "  ('4740_08', 0.7081842422485352),\n",
       "  ('4740_20', 0.7081177234649658),\n",
       "  ('4740_25', 0.7065144777297974),\n",
       "  ('4740_04', 0.7038346529006958)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    三脚（正解＝4740）\n",
    "'''\n",
    "predict('三脚', _bot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-3) 教師データに存在しない、単語１語だけの質問文\n",
    "\n",
    "類似度が0.5を下回る結果となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['こんにちは'],\n",
       " [('4678_3855', 0.18185651302337646),\n",
       "  ('4678_1848', 0.17963336408138275),\n",
       "  ('4678_1847', 0.17834149301052094),\n",
       "  ('4678_3856', 0.1740313172340393),\n",
       "  ('4808_82', 0.1726617068052292),\n",
       "  ('4808_175', 0.16706125438213348),\n",
       "  ('4678_1226', 0.16010412573814392),\n",
       "  ('4678_308', 0.1553257256746292),\n",
       "  ('4808_88', 0.15404954552650452),\n",
       "  ('4678_3234', 0.15360639989376068)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    こんにちは（正解＝なし）\n",
    "'''\n",
    "predict('こんにちは', _bot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-4) 正解は教師データにないが、一部品詞が合致している質問文\n",
    "\n",
    "4821、4837といったところが候補となり、類似度が0.5を上回る結果となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['よい', 'ソフト', '見る'],\n",
       " [('4837_18', 0.5997801423072815),\n",
       "  ('4837_09', 0.5964978933334351),\n",
       "  ('4837_02', 0.5954316258430481),\n",
       "  ('4837_03', 0.5942075252532959),\n",
       "  ('4837_10', 0.5915302038192749),\n",
       "  ('4837_01', 0.5886266231536865),\n",
       "  ('4837_11', 0.5882911682128906),\n",
       "  ('4837_00', 0.5872790813446045),\n",
       "  ('4837_19', 0.5868154168128967),\n",
       "  ('4821_40', 0.5860151648521423)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    よいソフトがあれば見たい（正解＝なし）\n",
    "'''\n",
    "predict('よいソフトがあれば見たい', _bot_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ご参考：教師データと一部品詞が合致する例\n",
    "\n",
    "- '使いたいソフトがある'（正解＝4837）['使う', 'ソフト']\n",
    "\n",
    "- '表計算ソフトについて'（正解＝4821）['表計算', 'ソフト']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-5) 正解が教師データに存在せず、合致する品詞も無い質問文\n",
    "\n",
    "類似度は、0.5を大幅に下回る結果となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['おいしい', 'ラーメン', '食べる'],\n",
       " [('4678_2906', 0.268244206905365),\n",
       "  ('4678_898', 0.26373547315597534),\n",
       "  ('4678_2907', 0.2627856135368347),\n",
       "  ('4678_899', 0.2614479064941406),\n",
       "  ('4709_04', 0.2589472234249115),\n",
       "  ('4709_13', 0.2562527656555176),\n",
       "  ('4707_04', 0.25339412689208984),\n",
       "  ('4707_02', 0.2533625364303589),\n",
       "  ('4678_3132', 0.2519910931587219),\n",
       "  ('4678_1124', 0.24852317571640015)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    おいしいラーメンが食べたいです（正解＝なし）\n",
    "'''\n",
    "predict('おいしいラーメンが食べたいです', _bot_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
