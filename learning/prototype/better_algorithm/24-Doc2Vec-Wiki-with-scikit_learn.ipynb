{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Doc2vecの文書ベクトルを使用し、scikit-learnでコサイン類似検索\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Wikipediaの文書からDoc2Vecモデルを生成\n",
    "\n",
    "\n",
    "- scikit-learnのcosine-simularityを使用して類似検索\n",
    "\n",
    "\n",
    "下記レポート作成時のモデルファイルをそのまま使用しています。\n",
    "\n",
    "<a href=\"23-Doc2Vec-with-Wiki.ipynb\"><b>23-Doc2Vec-with-Wiki.ipynb</b></a>\n",
    "\n",
    "\n",
    "nosetestsの質問文を使用してテストしたところ、４問中１問だけが正解、という結果に終わりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) Wikipediaコンテンツファイルから全文書を抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "レポート <a href=\"31-Wikipedia-contents-csv.ipynb\"><b>31-Wikipedia-contents-csv.ipynb</b></a> の手順にて、いったんローカルPCにCSVファイル化しておきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) Wikipedia文書を学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "レポート <a href=\"23-Doc2Vec-with-Wiki.ipynb\"><b>23-Doc2Vec-with-Wiki.ipynb</b></a> の手順にて生成したDoc2Vecモデルファイルをロードして使用します。\n",
    "\n",
    "上記手順では、Wikipedia文書のみを使用し、ボキャブラリ／単語ベクトルの生成および学習を行い、モデルをファイル保存しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    環境準備\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "def doc2vec_model_path(dm):\n",
    "    model_path = 'prototype/better_algorithm/doc2vec.wikipedia.PV%d.model' % dm\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vector size=87181\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    あらかじめ学習したモデルのファイルをロード\n",
    "    dm = 0 : DBoWを使用したモデル\n",
    "'''\n",
    "dm = 0\n",
    "loaded_model_dbow = models.Doc2Vec.load(doc2vec_model_path(dm))\n",
    "\n",
    "print('Document vector size=%d' % (len(loaded_model_dbow.docvecs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) my-opeの文書を、Wikiから生成したモデルにより文書ベクトル化する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Wikipedia文書だけで学習されたDoc2Vecモデルを使用し、my-ope文書（質問文）をベクトル化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from learning.core.learn.learning_parameter import LearningParameter\n",
    "from learning.core.datasource import Datasource\n",
    "\n",
    "_bot_id = 13 # toyotsu_human.csv\n",
    "attr = {\n",
    "    'include_failed_data': False,\n",
    "    'include_tag_vector': False,\n",
    "    'classify_threshold': 0.5,\n",
    "    'algorithm': LearningParameter.ALGORITHM_LOGISTIC_REGRESSION,\n",
    "    'params_for_algorithm': {'C': 140},\n",
    "    'excluded_labels_for_fitting': None\n",
    "}\n",
    "learning_parameter = LearningParameter(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from learning.core.nlang import Nlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_document_vector(question, model, warning):\n",
    "    '''\n",
    "        question: \n",
    "            分かち書きされていない文書\n",
    "        model:\n",
    "            Doc2Vecの学習済みモデル\n",
    "            （検証時は品詞を落としていないWikipedia文書からモデルを生成）\n",
    "\n",
    "        inferred_vector:\n",
    "            文書を分かち書きしたコーパスから、\n",
    "            Doc2Vecの学習済みモデルを使用して\n",
    "            生成される類似文書ベクトル\n",
    "            （learning.core.nlang.Nlangの仕様に従い、\n",
    "            　一部品詞が落とされます。）\n",
    "\n",
    "        warning:\n",
    "            Trueを指定時、コーパスに含まれる単語が\n",
    "            モデル内のWord2Vecボキャブラリにない場合、\n",
    "            警告を表示する\n",
    "    '''\n",
    "    corpus = Nlang.split(question).split()\n",
    "    inferred_vector = model.infer_vector(corpus)\n",
    "    \n",
    "    if warning:\n",
    "        for c in corpus:\n",
    "            if not c in model.wv.vocab:\n",
    "                print(\"Warning: word [%s] does not exist in Word2Vec vocabulary.\" % c)\n",
    "\n",
    "    return inferred_vector\n",
    "\n",
    "def get_document_vectors(questions, model, warning=False):\n",
    "    document_vectors = []\n",
    "    for question in questions:\n",
    "        inferred_vector = get_document_vector(question, model, warning)\n",
    "        document_vectors.append(list(inferred_vector))\n",
    "\n",
    "    return np.array(document_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (4) コサイン類似検索の実行\n",
    "\n",
    "質問文は、my-ope プロダクションの nosetests テストケースから引用しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from learning.core.datasource import Datasource\n",
    "\n",
    "def search_simiarity(question, dbow_model):\n",
    "    '''\n",
    "        質問文間でコサイン類似度を算出して、近い質問文の候補を取得する\n",
    "        \n",
    "        仕様はプロダクションに準拠しています\n",
    "        ただし、文書のベクトル化は、TF-IDFではなく、\n",
    "        Doc2Vecを使用します。\n",
    "    '''\n",
    "    datasource = Datasource('csv')\n",
    "    question_answers = datasource.question_answers_for_suggest(_bot_id, question)\n",
    "\n",
    "    #all_array = TextArray(question_answers['question'], vectorizer=self.vectorizer)\n",
    "    #question_array = TextArray([question], vectorizer=self.vectorizer)\n",
    "    all_array      = get_document_vectors(question_answers['question'], dbow_model)\n",
    "    question_array = get_document_vectors([question], dbow_model, warning=True)\n",
    "    \n",
    "    print('count: my-ope all questions=%d, document vectors=%d (features=%d)' % (\n",
    "        np.size(question_answers['question']), all_array.shape[0], all_array.shape[1]\n",
    "    ))    \n",
    "    print('count: question=%d, document vectors=%d (features=%d)' % (\n",
    "        np.size([question]), question_array.shape[0], question_array.shape[1]\n",
    "    ))    \n",
    "\n",
    "    similarities = cosine_similarity(all_array, question_array)\n",
    "    similarities = similarities.flatten()\n",
    "\n",
    "    ordered_result = list(map(lambda x: {\n",
    "        'question_answer_id': float(x[0]), 'similarity': x[1], 'answer_id': x[2]\n",
    "    }, sorted(zip(question_answers['id'], similarities, question_answers['answer_id']), key=lambda x: x[1], reverse=True)))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(ordered_result)\n",
    "\n",
    "    print(df[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/30 PM 01:30:48 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/30 PM 01:30:48 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: word [ＪＡＬ] does not exist in Word2Vec vocabulary.\n",
      "Warning: word [マイレージ] does not exist in Word2Vec vocabulary.\n",
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "   answer_id  question_answer_id  similarity\n",
      "0       6976             13556.0    0.173428\n",
      "1       6910             13484.0    0.162010\n",
      "2       6949             13529.0    0.161308\n",
      "3       6946             13525.0    0.160166\n",
      "4       6738             13309.0    0.156441\n",
      "5       6934             13513.0    0.152932\n",
      "6       6892             13466.0    0.152278\n",
      "7       6865             13439.0    0.145302\n",
      "8       6779             13352.0    0.143245\n",
      "9       6713             13283.0    0.143054\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6803\n",
    "search_simiarity('JAL マイレージ', loaded_model_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/30 PM 01:30:48 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/30 PM 01:30:48 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "   answer_id  question_answer_id  similarity\n",
      "0       6856             13430.0    0.516781\n",
      "1       6763             13335.0    0.505366\n",
      "2       6888             13462.0    0.493470\n",
      "3       6786             13359.0    0.463074\n",
      "4       6744             13316.0    0.458465\n",
      "5       6863             13437.0    0.455485\n",
      "6       6762             13334.0    0.444064\n",
      "7       6733             13304.0    0.439248\n",
      "8       6824             13398.0    0.436261\n",
      "9       6749             13310.0    0.433721\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6763\n",
    "search_simiarity('海外の出張費の精算の方法は？', loaded_model_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/30 PM 01:30:48 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/30 PM 01:30:48 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "   answer_id  question_answer_id  similarity\n",
      "0       6787             13360.0    0.356194\n",
      "1       6893             13467.0    0.354752\n",
      "2       6799             13374.0    0.344399\n",
      "3       6767             13339.0    0.338896\n",
      "4       6772             13361.0    0.336147\n",
      "5       6862             13436.0    0.324125\n",
      "6       6796             13371.0    0.321354\n",
      "7       6798             13373.0    0.320444\n",
      "8       6900             13474.0    0.306015\n",
      "9       6912             13489.0    0.305509\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6767\n",
    "search_simiarity('VISAの勘定科目がわからない', loaded_model_dbow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/30 PM 01:30:49 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/30 PM 01:30:49 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "   answer_id  question_answer_id  similarity\n",
      "0       6909             13483.0    0.415835\n",
      "1       6723             13294.0    0.410651\n",
      "2       6956             13536.0    0.337485\n",
      "3       6958             13538.0    0.315778\n",
      "4       6980             13560.0    0.307432\n",
      "5       6949             13529.0    0.304626\n",
      "6       6988             13568.0    0.301286\n",
      "7       7011             13591.0    0.300313\n",
      "8       6957             13537.0    0.288305\n",
      "9       6912             13488.0    0.283848\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6909\n",
    "search_simiarity('子供が生まれた', loaded_model_dbow) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
