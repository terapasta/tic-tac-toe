{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Doc2vecの文書ベクトルを使用し、scikit-learnでコサイン類似検索\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Wikipediaの文書からDoc2Vecモデルを生成\n",
    "\n",
    "\n",
    "- scikit-learnのcosine-simularityを使用して類似検索\n",
    "\n",
    "\n",
    "nosetestsの質問文を使用してテストしたところ、４問中３問が正解、という結果を得ました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) Wikipediaコンテンツファイルから全文書を抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "レポート <a href=\"31-Wikipedia-contents-csv.ipynb\"><b>31-Wikipedia-contents-csv.ipynb</b></a> の手順にて、いったんローカルPCにCSVファイル化しておきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) Wikipedia文書を学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "レポート <a href=\"27-Create-doc2vec-model-wiki.ipynb\"><b>27-Create-doc2vec-model-wiki.ipynb</b></a> の手順にて生成したDoc2Vecモデルファイルをロードして使用します。\n",
    "\n",
    "上記手順では、Wikipedia文書のみを使用し、ボキャブラリ／単語ベクトルの生成および学習を行い、モデルをファイル保存しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    環境準備\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "def doc2vec_model_path(dm):\n",
    "    model_path = 'prototype/better_algorithm/doc2vec.wikipedia.PV%d.model' % dm\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vector size=431680\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    あらかじめ学習したモデルのファイルをロード\n",
    "    dm = 0 : DBoWを使用したモデル\n",
    "'''\n",
    "dm = 0\n",
    "loaded_model_dbow = models.Doc2Vec.load(doc2vec_model_path(dm))\n",
    "\n",
    "print('Document vector size=%d' % (len(loaded_model_dbow.docvecs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) my-opeの文書を、Wikiから生成したモデルにより文書ベクトル化する関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Wikipedia文書だけで学習されたDoc2Vecモデルを使用し、my-ope文書（質問文）をベクトル化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from learning.core.learn.learning_parameter import LearningParameter\n",
    "from learning.core.datasource import Datasource\n",
    "\n",
    "_bot_id = 13 # toyotsu_human.csv\n",
    "attr = {\n",
    "    'include_failed_data': False,\n",
    "    'include_tag_vector': False,\n",
    "    'classify_threshold': 0.5,\n",
    "    'algorithm': LearningParameter.ALGORITHM_LOGISTIC_REGRESSION,\n",
    "    'params_for_algorithm': {'C': 140},\n",
    "    'excluded_labels_for_fitting': None\n",
    "}\n",
    "learning_parameter = LearningParameter(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from learning.core.nlang import Nlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_document_vector(question, model, warning):\n",
    "    '''\n",
    "        question: \n",
    "            分かち書きされていない文書\n",
    "        model:\n",
    "            Doc2Vecの学習済みモデル\n",
    "            （検証時は品詞を落としていないWikipedia文書からモデルを生成）\n",
    "\n",
    "        inferred_vector:\n",
    "            文書を分かち書きしたコーパスから、\n",
    "            Doc2Vecの学習済みモデルを使用して\n",
    "            生成される類似文書ベクトル\n",
    "            （learning.core.nlang.Nlangの仕様に従い、\n",
    "            　一部品詞が落とされます。）\n",
    "\n",
    "            非常にサンプル数が多いので、類似文書ベクトル生成時の\n",
    "            学習レート[alpha]を小さく設定し、かつ、\n",
    "            反復回数[steps]を大幅に増加させています。\n",
    "\n",
    "        warning:\n",
    "            Trueを指定時、コーパスに含まれる単語が\n",
    "            モデル内のWord2Vecボキャブラリにない場合、\n",
    "            警告を表示する\n",
    "    '''\n",
    "    corpus = Nlang.split(question).split()\n",
    "    inferred_vector = model.infer_vector(corpus, alpha=0.01, min_alpha=0.0001, steps=1000)\n",
    "    \n",
    "    if warning:\n",
    "        for c in corpus:\n",
    "            if not c in model.wv.vocab:\n",
    "                print(\"Warning: word [%s] does not exist in Word2Vec vocabulary.\" % c)\n",
    "\n",
    "    return inferred_vector\n",
    "\n",
    "def get_document_vectors(questions, model, warning=False):\n",
    "    document_vectors = []\n",
    "    for question in questions:\n",
    "        inferred_vector = get_document_vector(question, model, warning)\n",
    "        document_vectors.append(list(inferred_vector))\n",
    "\n",
    "    return np.array(document_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (4) コサイン類似検索の実行\n",
    "\n",
    "質問文は、my-ope プロダクションの nosetests テストケースから引用しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from learning.core.datasource import Datasource\n",
    "import time\n",
    "\n",
    "def search_simiarity(question, dbow_model):\n",
    "    '''\n",
    "        質問文間でコサイン類似度を算出して、近い質問文の候補を取得する\n",
    "        \n",
    "        仕様はプロダクションに準拠しています\n",
    "        ただし、文書のベクトル化は、TF-IDFではなく、\n",
    "        Doc2Vecを使用します。\n",
    "    '''\n",
    "    start = time.time()\n",
    "\n",
    "    datasource = Datasource('csv')\n",
    "    question_answers = datasource.question_answers_for_suggest(_bot_id, question)\n",
    "\n",
    "    #all_array = TextArray(question_answers['question'], vectorizer=self.vectorizer)\n",
    "    #question_array = TextArray([question], vectorizer=self.vectorizer)\n",
    "    all_array      = get_document_vectors(question_answers['question'], dbow_model)\n",
    "    question_array = get_document_vectors([question], dbow_model, warning=True)\n",
    "    \n",
    "    print('count: my-ope all questions=%d, document vectors=%d (features=%d)' % (\n",
    "        np.size(question_answers['question']), all_array.shape[0], all_array.shape[1]\n",
    "    ))    \n",
    "    print('count: question=%d, document vectors=%d (features=%d)' % (\n",
    "        np.size([question]), question_array.shape[0], question_array.shape[1]\n",
    "    ))    \n",
    "\n",
    "    similarities = cosine_similarity(all_array, question_array)\n",
    "    similarities = similarities.flatten()\n",
    "\n",
    "    ordered_result = list(map(lambda x: {\n",
    "        'question_answer_id': float(x[0]), 'similarity': x[1], 'answer_id': x[2]\n",
    "    }, sorted(zip(question_answers['id'], similarities, question_answers['answer_id']), key=lambda x: x[1], reverse=True)))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(ordered_result)\n",
    "\n",
    "    print(df[0:20])\n",
    "    elapsed_time =  time.time() - start\n",
    "    print(\"elapsed %d seconds\" % elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/31 AM 11:38:57 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/31 AM 11:38:57 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "    answer_id  question_answer_id  similarity\n",
      "0        6803             13378.0    0.616117\n",
      "1        6775             13348.0    0.584991\n",
      "2        6777             13350.0    0.579579\n",
      "3        6890             13464.0    0.541347\n",
      "4        6868             13442.0    0.538769\n",
      "5        6774             13346.0    0.538247\n",
      "6        6774             13347.0    0.522670\n",
      "7        6735             13306.0    0.509320\n",
      "8        6804             13379.0    0.507522\n",
      "9        6809             13337.0    0.505009\n",
      "10       6850             13424.0    0.504672\n",
      "11       6999             13579.0    0.500682\n",
      "12       6801             13376.0    0.500465\n",
      "13       6790             13364.0    0.495466\n",
      "14       6833             13407.0    0.493634\n",
      "15       7021             13600.0    0.490861\n",
      "16       6811             13385.0    0.488157\n",
      "17       6738             13309.0    0.487759\n",
      "18       6787             13360.0    0.484816\n",
      "19       6987             13567.0    0.484704\n",
      "elapsed 8 seconds\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6803\n",
    "search_simiarity('JAL マイレージ', loaded_model_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/31 AM 11:39:05 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/31 AM 11:39:05 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "    answer_id  question_answer_id  similarity\n",
      "0        6763             13335.0    0.793270\n",
      "1        6876             13450.0    0.728564\n",
      "2        6830             13404.0    0.714666\n",
      "3        6745             13317.0    0.691611\n",
      "4        6856             13430.0    0.685585\n",
      "5        6762             13334.0    0.684438\n",
      "6        6868             13442.0    0.679503\n",
      "7        6743             13314.0    0.672276\n",
      "8        6827             13401.0    0.671643\n",
      "9        6824             13398.0    0.669952\n",
      "10       6863             13437.0    0.666715\n",
      "11       6740             13311.0    0.665067\n",
      "12       6749             13310.0    0.654500\n",
      "13       6744             13316.0    0.651408\n",
      "14       6902             13476.0    0.650846\n",
      "15       6733             13304.0    0.647228\n",
      "16       6898             13472.0    0.638212\n",
      "17       6802             13377.0    0.634993\n",
      "18       6873             13447.0    0.633423\n",
      "19       6759             13331.0    0.627815\n",
      "elapsed 8 seconds\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6763\n",
    "search_simiarity('海外の出張費の精算の方法は？', loaded_model_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/31 AM 11:39:13 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/31 AM 11:39:13 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "    answer_id  question_answer_id  similarity\n",
      "0        6787             13360.0    0.721095\n",
      "1        6767             13339.0    0.696659\n",
      "2        6797             13372.0    0.686938\n",
      "3        6900             13474.0    0.683477\n",
      "4        6799             13374.0    0.678541\n",
      "5        6796             13371.0    0.674079\n",
      "6        6772             13361.0    0.648443\n",
      "7        6893             13467.0    0.620368\n",
      "8        6782             13355.0    0.610084\n",
      "9        6791             13366.0    0.608042\n",
      "10       6790             13365.0    0.602482\n",
      "11       6794             13369.0    0.596453\n",
      "12       6889             13463.0    0.576385\n",
      "13       6890             13464.0    0.569637\n",
      "14       6790             13364.0    0.566126\n",
      "15       6781             13354.0    0.565036\n",
      "16       6795             13370.0    0.559821\n",
      "17       6801             13376.0    0.553004\n",
      "18       6800             13375.0    0.552489\n",
      "19       6789             13363.0    0.537808\n",
      "elapsed 8 seconds\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6767\n",
    "search_simiarity('VISAの勘定科目がわからない', loaded_model_dbow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/05/31 AM 11:39:22 ['./fixtures/learning_training_messages/benefitone.csv', './fixtures/learning_training_messages/ptna.csv', './fixtures/learning_training_messages/septeni.csv', './fixtures/learning_training_messages/toyotsu_human.csv']\n",
      "2017/05/31 AM 11:39:22 ['./fixtures/question_answers/toyotsu_human.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: my-ope all questions=317, document vectors=317 (features=200)\n",
      "count: question=1, document vectors=1 (features=200)\n",
      "    answer_id  question_answer_id  similarity\n",
      "0        6909             13483.0    0.637177\n",
      "1        6870             13444.0    0.541225\n",
      "2        6777             13350.0    0.512139\n",
      "3        6924             13503.0    0.486039\n",
      "4        6871             13445.0    0.485358\n",
      "5        7021             13600.0    0.472638\n",
      "6        7009             13589.0    0.468125\n",
      "7        6774             13346.0    0.466784\n",
      "8        6776             13349.0    0.460481\n",
      "9        6836             13410.0    0.458075\n",
      "10       6913             13491.0    0.457961\n",
      "11       6775             13348.0    0.457753\n",
      "12       6846             13420.0    0.457714\n",
      "13       6774             13347.0    0.454071\n",
      "14       6990             13570.0    0.451012\n",
      "15       6980             13560.0    0.450422\n",
      "16       7007             13587.0    0.441555\n",
      "17       6877             13451.0    0.439786\n",
      "18       6755             13303.0    0.439723\n",
      "19       6950             13530.0    0.439125\n",
      "elapsed 8 seconds\n"
     ]
    }
   ],
   "source": [
    "# 正解＝6909\n",
    "search_simiarity('子供が生まれた', loaded_model_dbow) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
