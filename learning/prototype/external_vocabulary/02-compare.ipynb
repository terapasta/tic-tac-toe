{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TF-IDF値の算出結果比較\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) 指定BotのTFIDF値を、全Botの学習セットを使用して算出\n",
    "\n",
    "ベクトライズにはすべてのBotの学習セットを使用しますが、ターゲット「test_toyotsu_human_conversation.csv」に対応するTFIDF値のベクトルだけを取得するようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    テスト環境を準備するためのモジュールを使用します。\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)\n",
    "\n",
    "from prototype.modules import TestTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_benefitone_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_daikin_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_ptna_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_toyotsu_human_conversation.csv]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    データファイルは、既存の訓練データを別場所にコピーしてから使用します\n",
    "    テストデータは、csv_file_name で指定した複数件のファイルを使用します。\n",
    "'''\n",
    "csv_file_names = [\n",
    "    'test_benefitone_conversation.csv',\n",
    "    'test_daikin_conversation.csv',\n",
    "    'test_ptna_conversation.csv',\n",
    "    'test_toyotsu_human_conversation.csv'\n",
    "]\n",
    "temp_path = TestTool.copy_testdata_csv(learning_dir, csv_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_dataset_names_array(dataset_name, count):\n",
    "    '''\n",
    "        データセット名称のリストを生成\n",
    "    '''\n",
    "    dataset_name_list = [dataset_name] * count\n",
    "    dataset_names = np.array(dataset_name_list)\n",
    "    return dataset_names\n",
    "\n",
    "\n",
    "'''\n",
    "    学習セットの全CSVファイルから、\n",
    "    質問文の配列を生成\n",
    "'''\n",
    "questions_all = np.empty(0)\n",
    "answer_ids_all = np.empty(0)\n",
    "dataset_names_all = np.empty(0)\n",
    "\n",
    "for csv_file_path in temp_path:\n",
    "    '''\n",
    "        TrainingMessageFromCsv と同様の処理\n",
    "\n",
    "        CSVファイル--->pandasデータフレームの生成\n",
    "        (TrainingMessageFromCsv#__build_learning_training_messages)\n",
    "    '''\n",
    "    learning_training_messages = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "    questions = np.array(learning_training_messages['question'])\n",
    "    answer_ids = np.array(learning_training_messages['answer_id'])\n",
    "    dataset_names = get_dataset_names_array(os.path.basename(csv_file_path), learning_training_messages.shape[0])\n",
    "\n",
    "    questions_all = np.concatenate((questions_all, questions))\n",
    "    answer_ids_all = np.concatenate((answer_ids_all, answer_ids))\n",
    "    dataset_names_all = np.concatenate((dataset_names_all, dataset_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31180"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    TextArray#__init__ と同様の処理\n",
    "'''\n",
    "from learning.core.nlang import Nlang\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sentences = np.array(questions_all)\n",
    "separated_sentences = Nlang.batch_split(sentences)\n",
    "np.size(separated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    TextArray#to_vec と同様の処理\n",
    "'''\n",
    "vectorizer = TfidfVectorizer(use_idf=True, token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "vectorizer.fit(separated_sentences)\n",
    "feature_vectors = vectorizer.transform(separated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31180x3162 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 243448 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    指定Botに対応するデータのインデックスを取得\n",
    "'''\n",
    "target_data_set_name = 'test_toyotsu_human_conversation.csv'\n",
    "target_indices = np.where(dataset_names_all==target_data_set_name)\n",
    "np.size(target_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([26116, 26117, 26118, ..., 31177, 31178, 31179]),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5064x3162 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 49382 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    指定Botに対応するTFIDF値だけを抽出する\n",
    "    --->これが指定Botの学習＋予測に使用されるベクトルになります\n",
    "'''\n",
    "target_feature_vectors = feature_vectors[target_indices]\n",
    "target_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1-1) 指定Botにおける頻出単語を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words_with_frequency(vectorizer, feature_vectors):\n",
    "    bools = (feature_vectors > 0)\n",
    "    sums = np.sum(bools, axis=0)\n",
    "    frequency_array = np.array(sums)[0]\n",
    "    \n",
    "    words_with_frequency = []\n",
    "    for item in vectorizer.vocabulary_.items():\n",
    "        k, v = item\n",
    "        freq = frequency_array[v] # 対象Botに出現しない単語の場合、値は0\n",
    "        if freq > 0:\n",
    "            words_with_frequency.append((k, v, freq))\n",
    "\n",
    "    return words_with_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    ボキャブラリの単語について、\n",
    "    インデックスおよび出現数を取得\n",
    "'''\n",
    "words_with_frequency = get_words_with_frequency(vectorizer, target_feature_vectors)\n",
    "len(words_with_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('する', 159, 2722),\n",
       " ('出張', 1216, 800),\n",
       " ('保険', 1109, 770),\n",
       " ('場合', 1455, 766),\n",
       " ('海外', 2093, 744),\n",
       " ('退職', 2642, 744),\n",
       " ('申請', 2193, 600),\n",
       " ('なる', 232, 564),\n",
       " ('科目', 2270, 522),\n",
       " ('勘定', 1274, 512),\n",
       " ('書', 1929, 504),\n",
       " ('れる', 322, 498),\n",
       " ('精算', 2319, 482),\n",
       " ('健康', 1129, 476),\n",
       " ('教える', 1846, 456),\n",
       " ('どう', 212, 454),\n",
       " ('できる', 200, 438),\n",
       " ('ない', 221, 432),\n",
       " ('いい', 14, 424),\n",
       " ('金', 2724, 384)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    出現回数の降順に並べ替えます\n",
    "'''\n",
    "sorted_words_list_target = sorted(words_with_frequency, key=lambda x: x[2], reverse=True)\n",
    "sorted_words_list_target[:20] # 上位２０件を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1-2) 全Botにおける頻出単語を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_with_frequency_all = get_words_with_frequency(vectorizer, feature_vectors)\n",
    "len(words_with_frequency_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('する', 159, 15282),\n",
       " ('メール', 819, 4790),\n",
       " ('ない', 221, 4431),\n",
       " ('れる', 322, 3811),\n",
       " ('できる', 200, 3734),\n",
       " ('教える', 1846, 2828),\n",
       " ('２０１０', 2855, 2700),\n",
       " ('ｏｕｔｌｏｏｋ', 3071, 2515),\n",
       " ('暗号', 1923, 2252),\n",
       " ('どう', 212, 1958),\n",
       " ('設定', 2509, 1940),\n",
       " ('表示', 2436, 1935),\n",
       " ('方法', 1876, 1930),\n",
       " ('なる', 232, 1776),\n",
       " ('インストール', 375, 1760),\n",
       " ('ｅ', 2959, 1721),\n",
       " ('管理', 2312, 1692),\n",
       " ('いい', 14, 1643),\n",
       " ('知る', 2239, 1575),\n",
       " ('利用', 1252, 1528)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    出現回数の降順に並べ替えます\n",
    "'''\n",
    "sorted_words_list_all = sorted(words_with_frequency_all, key=lambda x: x[2], reverse=True)\n",
    "sorted_words_list_all[:20] # 上位２０件を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1-3) 調査で使用する最頻出単語を決める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    ここで調査する最頻出単語は、\n",
    "    全Bot、指定Bot で共通して\n",
    "    頻出している５件の単語に限定してみます。\n",
    "'''\n",
    "most_freq_words = ['する', 'れる', 'どう', 'できる', 'ない']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 単独BotにおけるTFIDF値を算出\n",
    "\n",
    "プロダクションコードと同様の処理で、単独Botの学習セットを使用してTFIDF値を算出します。\n",
    "\n",
    "ターゲットは「test_toyotsu_human_conversation.csv」です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tfidf_for_one_target(csv_file_path):\n",
    "    '''\n",
    "        TrainingMessageFromCsv と同様の処理\n",
    "\n",
    "        CSVファイル--->pandasデータフレームの生成\n",
    "        (TrainingMessageFromCsv#__build_learning_training_messages)\n",
    "    '''\n",
    "    learning_training_messages = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "    questions = np.array(learning_training_messages['question'])\n",
    "    answer_ids = np.array(learning_training_messages['answer_id'])\n",
    "\n",
    "    '''\n",
    "        TextArray#__init__ と同様の処理\n",
    "    '''\n",
    "    sentences = np.array(questions)\n",
    "    separated_sentences = Nlang.batch_split(sentences)\n",
    "    np.size(separated_sentences)\n",
    "\n",
    "    '''\n",
    "        TextArray#to_vec と同様の処理\n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(use_idf=True, token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "    vectorizer.fit(separated_sentences)\n",
    "    feature_vectors = vectorizer.transform(separated_sentences)\n",
    "    \n",
    "    return questions, vectorizer, feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    ベクトライザー＆featureベクトルを生成\n",
    "'''\n",
    "csv_file_path = temp_path[3]\n",
    "questions, vectorizer_toyotsu, feature_vectors_toyotsu = get_tfidf_for_one_target(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    ボキャブラリの単語について、\n",
    "    インデックスおよび出現数を取得\n",
    "'''\n",
    "words_with_frequency_toyotsu = get_words_with_frequency(vectorizer_toyotsu, feature_vectors_toyotsu)\n",
    "len(words_with_frequency_toyotsu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) TFIDF値を比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[159, 322, 212, 200, 221]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    再頻出単語のインデックスを取得しておく\n",
    "'''\n",
    "index_target = []\n",
    "for word in most_freq_words:\n",
    "    for w, i, _ in words_with_frequency:\n",
    "        if w == word:\n",
    "            index_target.append(i)\n",
    "\n",
    "index_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 121, 71, 65, 80]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    再頻出単語のインデックスを取得しておく\n",
    "'''\n",
    "index_toyotsu = []\n",
    "for word in most_freq_words:\n",
    "    for w, i, _ in words_with_frequency_toyotsu:\n",
    "        if w == word:\n",
    "            index_toyotsu.append(i)\n",
    "\n",
    "index_toyotsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-1) TF-IDF値の変化を２０件ほど確認\n",
    "\n",
    "再頻出単語 'する', 'れる', 'どう', 'できる', 'ない' に対するTFIDF値が、概ね下がったことは確認できました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0  [する]0.159->0.132 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=1  [する]0.055->0.046 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=2  [する]0.062->0.049 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=6  [する]0.000->0.000 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.198->0.138 [ない]0.000->0.000\n",
      "index=7  [する]0.098->0.080 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=9  [する]0.116->0.093 [れる]0.000->0.000 [どう]0.122->0.102 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=10 [する]0.104->0.091 [れる]0.000->0.000 [どう]0.219->0.201 [できる]0.000->0.000 [ない]0.222->0.157\n",
      "index=11 [する]0.121->0.097 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=12 [する]0.000->0.000 [れる]0.000->0.000 [どう]0.184->0.185 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=13 [する]0.093->0.071 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=14 [する]0.000->0.000 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.170->0.118 [ない]0.000->0.000\n",
      "index=15 [する]0.092->0.072 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=16 [する]0.078->0.064 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=17 [する]0.136->0.113 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=18 [する]0.000->0.000 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.225->0.162\n",
      "index=19 [する]0.088->0.074 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=21 [する]0.090->0.076 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=23 [する]0.000->0.000 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.162->0.113\n",
      "index=24 [する]0.061->0.053 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.000->0.000\n",
      "index=25 [する]0.000->0.000 [れる]0.000->0.000 [どう]0.000->0.000 [できる]0.000->0.000 [ない]0.211->0.147\n"
     ]
    }
   ],
   "source": [
    "display_cnt = 0\n",
    "for index in range(feature_vectors_toyotsu.shape[0]):\n",
    "    data_toyotsu = feature_vectors_toyotsu.getrow(index).toarray()[0]\n",
    "    data_target = target_feature_vectors.getrow(index).toarray()[0]\n",
    "\n",
    "    if data_toyotsu[index_toyotsu[0]] == 0 and \\\n",
    "        data_toyotsu[index_toyotsu[1]] == 0 and \\\n",
    "        data_toyotsu[index_toyotsu[2]] == 0 and \\\n",
    "        data_toyotsu[index_toyotsu[3]] == 0 and \\\n",
    "        data_toyotsu[index_toyotsu[4]] == 0:\n",
    "        continue\n",
    "    \n",
    "    display_cnt += 1\n",
    "    print('index=%-2d [%s]%0.3f->%0.3f [%s]%0.3f->%0.3f [%s]%0.3f->%0.3f [%s]%0.3f->%0.3f [%s]%0.3f->%0.3f' % (\n",
    "        index,\n",
    "        most_freq_words[0],\n",
    "        data_toyotsu[index_toyotsu[0]],\n",
    "        data_target[index_target[0]],\n",
    "        most_freq_words[1],\n",
    "        data_toyotsu[index_toyotsu[1]],\n",
    "        data_target[index_target[1]],\n",
    "        most_freq_words[2],\n",
    "        data_toyotsu[index_toyotsu[2]],\n",
    "        data_target[index_target[2]],\n",
    "        most_freq_words[3],\n",
    "        data_toyotsu[index_toyotsu[3]],\n",
    "        data_target[index_target[3]],\n",
    "        most_freq_words[4],\n",
    "        data_toyotsu[index_toyotsu[4]],\n",
    "        data_target[index_target[4]],\n",
    "    ))\n",
    "    \n",
    "    if display_cnt == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-2) 任意の質問文について、TF-IDF値の変化を確認\n",
    "\n",
    "頻出単語の重みが低下し、その他の単語の重みが増していることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_item_from_vocabulary(vocabulary, index):\n",
    "    '''\n",
    "        vocabulary から指定インデックスの単語を参照\n",
    "    '''\n",
    "    for k, v in vocabulary.items():\n",
    "        if v == index:\n",
    "            return k\n",
    "\n",
    "    return None\n",
    "\n",
    "def show_tfidf_values(question_index):\n",
    "    a = feature_vectors_toyotsu.getrow(question_index)\n",
    "    voc_idx_toyotsu = np.nonzero(a)[1]\n",
    "    data_toyotsu = np.array(a[np.nonzero(a)])[0]\n",
    "    b = target_feature_vectors.getrow(question_index)\n",
    "    data_target = np.array(b[np.nonzero(b)])[0]\n",
    "\n",
    "    print('question=%s' % questions[question_index])\n",
    "\n",
    "    for i, v in enumerate(data_toyotsu):\n",
    "        if v > 0: # TF-IDF値が0でないfeature\n",
    "            print('feature #%-2d %0.6f --> %0.6f (%s)' % (\n",
    "                i,\n",
    "                data_toyotsu[i],\n",
    "                data_target[i],\n",
    "                get_item_from_vocabulary(vectorizer_toyotsu.vocabulary_, voc_idx_toyotsu[i]),\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=「転勤者引越対応」引っ越し先が決まっていないが、どうしたらいいか。\n",
      "feature #0  0.223013 --> 0.210334 (いい)\n",
      "feature #1  0.103915 --> 0.091389 (する)\n",
      "feature #2  0.218639 --> 0.200982 (どう)\n",
      "feature #3  0.221817 --> 0.157428 (ない)\n",
      "feature #4  0.255266 --> 0.254752 (先)\n",
      "feature #5  0.334237 --> 0.259754 (対応)\n",
      "feature #6  0.422277 --> 0.448290 (引っ越し)\n",
      "feature #7  0.356499 --> 0.393562 (引越)\n",
      "feature #8  0.386878 --> 0.386063 (決まる)\n",
      "feature #9  0.233124 --> 0.252416 (者)\n",
      "feature #10 0.395164 --> 0.425731 (転勤)\n"
     ]
    }
   ],
   "source": [
    "show_tfidf_values(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=「VISA」VISA取得のための代金はどの勘定科目なのか？\n",
      "feature #0  0.428232 --> 0.401426 (代金)\n",
      "feature #1  0.223223 --> 0.263109 (勘定)\n",
      "feature #2  0.323515 --> 0.299934 (取得)\n",
      "feature #3  0.221913 --> 0.262114 (科目)\n",
      "feature #4  0.782868 --> 0.781643 (ｖｉｓａ)\n"
     ]
    }
   ],
   "source": [
    "show_tfidf_values(853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question=「勘定科目」出張していないが、現地でTMCとの交際費をTTC負担にしてほしいと 現地から依頼があったのですがその時のその処理について教えてもらえますか？\n",
      "feature #0  0.170939 --> 0.137977 (する)\n",
      "feature #1  0.182443 --> 0.118841 (ない)\n",
      "feature #2  0.262441 --> 0.207446 (ほしい)\n",
      "feature #3  0.318206 --> 0.316178 (交際)\n",
      "feature #4  0.309395 --> 0.286473 (依頼)\n",
      "feature #5  0.206003 --> 0.217873 (処理)\n",
      "feature #6  0.150003 --> 0.182998 (出張)\n",
      "feature #7  0.173502 --> 0.205681 (勘定)\n",
      "feature #8  0.179598 --> 0.136920 (教える)\n",
      "feature #9  0.473246 --> 0.507760 (現地)\n",
      "feature #10 0.172484 --> 0.204903 (科目)\n",
      "feature #11 0.195663 --> 0.219832 (負担)\n",
      "feature #12 0.191453 --> 0.207775 (費)\n",
      "feature #13 0.386728 --> 0.368502 (ｔｍｃ)\n",
      "feature #14 0.257163 --> 0.269565 (ｔｔｃ)\n"
     ]
    }
   ],
   "source": [
    "show_tfidf_values(975)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
