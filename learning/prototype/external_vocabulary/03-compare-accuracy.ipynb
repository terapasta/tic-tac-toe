{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TF-IDF値の算出結果比較 (accuracy比較)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) 結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy に大きな変化は見られませんでした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| テストデータ | サンプル数 | ラベル数 | accuracy（全Bot使用時） | <> | accuracy（単一Bot使用時） |\n",
    "| :--- | :---: | :---: | :---: | :---: | :---: |\n",
    "| test_benefitone_conversation | 4,117 | 85 | 0.985436893204 | == | 0.985436893204 |\n",
    "| test_daikin_conversation | 17,446 | 614 | 0.983723062815 | < | 0.984181568088 |\n",
    "| test_ptna_conversation | 4,562 | 70 | 0.973707274321 | > | 0.971954425942 |\n",
    "| test_toyotsu_human_conversation | 5,067 | 302 | 0.996842936069 | < | 0.998421468035 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) 全Botの学習セットを使用した場合\n",
    "\n",
    "指定BotのTFIDF値を、全Botの学習セットを使用して算出します。\n",
    "\n",
    "ベクトライズにはすべてのBotの学習セットを使用しますが、ターゲット「test_toyotsu_human_conversation.csv」に対応するTFIDF値のベクトルだけを取得するようにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1-1) 環境／テストデータ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    テスト環境を準備するためのモジュールを使用します。\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)\n",
    "\n",
    "from prototype.modules import TestTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_benefitone_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_daikin_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_ptna_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_toyotsu_human_conversation.csv]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    データファイルは、既存の訓練データを別場所にコピーしてから使用します\n",
    "    テストデータは、csv_file_name で指定した複数件のファイルを使用します。\n",
    "'''\n",
    "csv_file_names = [\n",
    "    'test_benefitone_conversation.csv',\n",
    "    'test_daikin_conversation.csv',\n",
    "    'test_ptna_conversation.csv',\n",
    "    'test_toyotsu_human_conversation.csv'\n",
    "]\n",
    "csv_file_paths = TestTool.copy_testdata_csv(learning_dir, csv_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1-2) 検証で使用する関数を準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from learning.core.training_set.text_array import TextArray\n",
    "\n",
    "'''\n",
    "    既存のクラス変数\n",
    "'''\n",
    "COUNT_OF_APPEND_BLANK = 3\n",
    "CLASSIFY_FAILED_ANSWER_ID = 0\n",
    "\n",
    "\n",
    "def get_all_dataframes_from_csv(csv_file_path):\n",
    "    '''\n",
    "        引数のファイルパス配下にある\n",
    "        全てのCSVファイルパスを取得\n",
    "    '''\n",
    "    csv_file_paths = []\n",
    "    upper_path = os.path.dirname(csv_file_path)\n",
    "    for f in os.listdir(upper_path):\n",
    "        if os.path.splitext(f)[1] == '.csv':\n",
    "            csv_file_paths.append(os.path.join(upper_path, f))\n",
    "    \n",
    "    '''\n",
    "        CSVファイルからpandasデータフレームを生成\n",
    "        特定Botのデータを抽出できるようにするため、\n",
    "        データセット名を列として追加\n",
    "    '''\n",
    "    dataframes = []\n",
    "    for path in csv_file_paths:        \n",
    "        learning_training_messages = pd.read_csv(path, encoding='utf-8')\n",
    "        learning_training_messages['dataset_name'] = os.path.basename(path)\n",
    "        dataframes.append(learning_training_messages)        \n",
    "\n",
    "    return pd.concat(dataframes)\n",
    "\n",
    "\n",
    "def build_all_training_set_from_csv(csv_file_path):\n",
    "    '''\n",
    "        TrainingMessageFromCsv#buildと同様の処理        \n",
    "\n",
    "        学習セットの全CSVファイルから、\n",
    "        質問文／ラベル、およびそれらが含まれる\n",
    "        データセット名の配列を生成\n",
    "    '''\n",
    "    learning_training_messages = get_all_dataframes_from_csv(csv_file_path)\n",
    "    questions = np.array(learning_training_messages['question'])\n",
    "    answer_ids = np.array(learning_training_messages['answer_id'])\n",
    "    dataset_names = np.array(learning_training_messages['dataset_name'])\n",
    "\n",
    "    '''\n",
    "        空のテキストにラベル0を対応付けるために\n",
    "        強制的にトレーニングセットを追加\n",
    "    '''\n",
    "    questions = np.append(questions, [''] * COUNT_OF_APPEND_BLANK)\n",
    "    answer_ids = np.append(answer_ids, [CLASSIFY_FAILED_ANSWER_ID] * COUNT_OF_APPEND_BLANK)\n",
    "\n",
    "    '''\n",
    "        特定Botのデータを抽出時、ラベル0が含まれるようにするため、\n",
    "        ラベル0のレコードと、引数のファイル名を関連づけておく\n",
    "    '''\n",
    "    target_data_set_name = os.path.basename(csv_file_path)\n",
    "    dataset_names = np.append(dataset_names, [target_data_set_name] * COUNT_OF_APPEND_BLANK)\n",
    "\n",
    "    '''\n",
    "        本来はTrainingMessageFromCsvクラスに内包される変数\n",
    "        \n",
    "        body_array: 生成されたボキャブラリを格納\n",
    "        x, y: 全BotのTF-IDF値が含まれている状態\n",
    "    '''\n",
    "    body_array = TextArray(questions) # \n",
    "    x_all = body_array.to_vec() \n",
    "    y_all = answer_ids\n",
    "    print('Count all: samples=%d, features=%d, labels=%d' % (\n",
    "        x_all.shape[0], x_all.shape[1], np.size(np.unique(y_all))\n",
    "    ))\n",
    "\n",
    "    '''\n",
    "        指定Botに関連づけられたデータのインデックスを取得し、\n",
    "        指定Botに対応するTFIDF値／ラベルだけを抽出する\n",
    "        --->これが指定Botの学習＋予測に使用されるベクトルx／ラベルyになります\n",
    "    '''\n",
    "    target_indices = np.where(dataset_names==target_data_set_name)\n",
    "    x = x_all[target_indices]\n",
    "    y = y_all[target_indices]\n",
    "    print('Count target[%s]: samples=%d, features=%d, labels=%d' % (\n",
    "        target_data_set_name, x.shape[0], x.shape[1], np.size(np.unique(y))\n",
    "    ))\n",
    "\n",
    "    return body_array, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Bot#__get_estimator から抜粋\n",
    "'''\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_estimator(training_set_x, training_set_y):\n",
    "    params = {'C': [10, 100, 140, 200]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid=params)\n",
    "    grid.fit(training_set_x, training_set_y)\n",
    "    estimator = grid.best_estimator_\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1-3) 個別のBotについて検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 02:57:32 TextArray#__init__ start\n",
      "2017/04/26 PM 02:58:00 TextArray#to_vec start\n",
      "2017/04/26 PM 02:58:00 TextArray#to_vec end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all: samples=31183, features=3162, labels=1068\n",
      "Count target[test_benefitone_conversation.csv]: samples=4117, features=3162, labels=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 02:58:09 self.threshold: 0.5\n",
      "2017/04/26 PM 02:58:10 Evaluator#evaluate#elapsed time: 826.369047 ms\n",
      "2017/04/26 PM 02:58:10 accuracy: 0.985436893204\n",
      "2017/04/26 PM 02:58:10 TextArray#__init__ start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985436893204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 02:58:33 TextArray#to_vec start\n",
      "2017/04/26 PM 02:58:33 TextArray#to_vec end\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all: samples=31183, features=3162, labels=1068\n",
      "Count target[test_daikin_conversation.csv]: samples=17446, features=3162, labels=614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:01:46 self.threshold: 0.5\n",
      "2017/04/26 PM 03:02:15 Evaluator#evaluate#elapsed time: 28901.390076 ms\n",
      "2017/04/26 PM 03:02:15 accuracy: 0.983723062815\n",
      "2017/04/26 PM 03:02:15 TextArray#__init__ start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983723062815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:02:30 TextArray#to_vec start\n",
      "2017/04/26 PM 03:02:31 TextArray#to_vec end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all: samples=31183, features=3162, labels=1068\n",
      "Count target[test_ptna_conversation.csv]: samples=4562, features=3162, labels=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:02:35 self.threshold: 0.5\n",
      "2017/04/26 PM 03:02:36 Evaluator#evaluate#elapsed time: 481.173992 ms\n",
      "2017/04/26 PM 03:02:36 accuracy: 0.973707274321\n",
      "2017/04/26 PM 03:02:36 TextArray#__init__ start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973707274321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:02:51 TextArray#to_vec start\n",
      "2017/04/26 PM 03:02:51 TextArray#to_vec end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count all: samples=31183, features=3162, labels=1068\n",
      "Count target[test_toyotsu_human_conversation.csv]: samples=5067, features=3162, labels=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:03:17 self.threshold: 0.5\n",
      "2017/04/26 PM 03:03:21 Evaluator#evaluate#elapsed time: 3832.440138 ms\n",
      "2017/04/26 PM 03:03:21 accuracy: 0.996842936069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996842936069\n"
     ]
    }
   ],
   "source": [
    "from learning.core.evaluator import Evaluator\n",
    "\n",
    "for target_csv_file_path in csv_file_paths:\n",
    "    '''\n",
    "        学習実行\n",
    "    '''\n",
    "    body_array, x, y = build_all_training_set_from_csv(target_csv_file_path)    \n",
    "    estimator = get_estimator(x, y)\n",
    "    \n",
    "    '''\n",
    "        accuracy算出\n",
    "    '''\n",
    "    evaluator = Evaluator()\n",
    "    evaluator.evaluate(estimator, x, y, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) 単一Botの学習セットだけを使用した場合\n",
    "\n",
    "従来の方法により実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:03:21 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 4114\n",
      "2017/04/26 PM 03:03:21 TextArray#__init__ start\n",
      "2017/04/26 PM 03:03:23 TextArray#to_vec start\n",
      "2017/04/26 PM 03:03:23 TextArray#to_vec end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count target[test_benefitone_conversation.csv]: samples=4117, features=644, labels=85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:03:27 self.threshold: 0.5\n",
      "2017/04/26 PM 03:03:28 Evaluator#evaluate#elapsed time: 414.023161 ms\n",
      "2017/04/26 PM 03:03:28 accuracy: 0.985436893204\n",
      "2017/04/26 PM 03:03:28 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 17443\n",
      "2017/04/26 PM 03:03:28 TextArray#__init__ start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985436893204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:03:38 TextArray#to_vec start\n",
      "2017/04/26 PM 03:03:38 TextArray#to_vec end\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count target[test_daikin_conversation.csv]: samples=17446, features=1911, labels=614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:06:51 self.threshold: 0.5\n",
      "2017/04/26 PM 03:07:16 Evaluator#evaluate#elapsed time: 24787.204981 ms\n",
      "2017/04/26 PM 03:07:16 accuracy: 0.984181568088\n",
      "2017/04/26 PM 03:07:16 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 4559\n",
      "2017/04/26 PM 03:07:16 TextArray#__init__ start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984181568088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:07:18 TextArray#to_vec start\n",
      "2017/04/26 PM 03:07:18 TextArray#to_vec end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count target[test_ptna_conversation.csv]: samples=4562, features=670, labels=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:07:22 self.threshold: 0.5\n",
      "2017/04/26 PM 03:07:23 Evaluator#evaluate#elapsed time: 446.985006 ms\n",
      "2017/04/26 PM 03:07:23 accuracy: 0.971954425942\n",
      "2017/04/26 PM 03:07:23 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 5064\n",
      "2017/04/26 PM 03:07:23 TextArray#__init__ start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971954425942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:07:26 TextArray#to_vec start\n",
      "2017/04/26 PM 03:07:26 TextArray#to_vec end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count target[test_toyotsu_human_conversation.csv]: samples=5067, features=1182, labels=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/04/26 PM 03:07:51 self.threshold: 0.5\n",
      "2017/04/26 PM 03:07:54 Evaluator#evaluate#elapsed time: 2945.917130 ms\n",
      "2017/04/26 PM 03:07:54 accuracy: 0.998421468035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998421468035\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Bot#learn と同様の処理\n",
    "'''\n",
    "from learning.core.training_set.training_message_from_csv import TrainingMessageFromCsv\n",
    "\n",
    "for target_csv_file_path in csv_file_paths:\n",
    "    '''\n",
    "        学習セットをCSVファイルから個別に取得し、\n",
    "        学習実行\n",
    "    '''\n",
    "    training_set = TrainingMessageFromCsv(None, target_csv_file_path, None)\n",
    "    training_set.build()\n",
    "    print('Count target[%s]: samples=%d, features=%d, labels=%d' % (\n",
    "        os.path.basename(target_csv_file_path), \n",
    "        training_set.x.shape[0], \n",
    "        training_set.x.shape[1], \n",
    "        np.size(np.unique(training_set.y))\n",
    "    ))\n",
    "    estimator = get_estimator(training_set.x, training_set.y)\n",
    "\n",
    "    '''\n",
    "        accuracy算出\n",
    "    '''\n",
    "    evaluator = Evaluator()\n",
    "    evaluator.evaluate(estimator, training_set.x, training_set.y, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
