{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# One-class SVM の詳細調査\n",
    "\n",
    "scikit-learn の <b>One-class SVM</b> について、さらに詳細調査を行いました。\n",
    "\n",
    "結論としては、一定の効果が得られることを確認しました（ただしデフォルトから所定のチューニングが必要）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) テストデータ／環境準備\n",
    "\n",
    "マイオペで使用しているテストデータ（learning/tests/engine/fixtures/ 配下のCSVファイル）をベースに動作確認を行います。\n",
    "\n",
    "動作確認にあたっては、MySQLdb に接続できないため、ローカル環境テスト用の Bot クラスを使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    テスト環境を準備するためのモジュールを使用します。\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)\n",
    "\n",
    "from prototype.modules import TestTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_benefitone_conversation.csv]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    データファイルは、既存の訓練データを別場所にコピーしてから使用します\n",
    "    テストデータは、csv_file_name で指定したものを使用します。\n",
    "'''\n",
    "csv_file_name = 'test_benefitone_conversation.csv'\n",
    "copied_csv_file_path = TestTool.copy_testdata_csv(learning_dir, csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) TF-IDFベクターの準備\n",
    "\n",
    "Bot クラス内に組み込まれている __build_training_set_from_csv 関数をバラして実行しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    初期設定\n",
    "    データファイル、エンコードを指定\n",
    "    内容は、learn.py を参考にしました。    \n",
    "'''\n",
    "from learning.core.learn.learning_parameter import LearningParameter\n",
    "attr = {\n",
    "    'include_failed_data': False,\n",
    "    'include_tag_vector': False,\n",
    "    'classify_threshold': None,\n",
    "    # 'algorithm': LearningParameter.ALGORITHM_NAIVE_BAYES\n",
    "    'algorithm': LearningParameter.ALGORITHM_LOGISTIC_REGRESSION,\n",
    "    # 'params_for_algorithm': { 'C': 200 }\n",
    "    'params_for_algorithm': {}\n",
    "}\n",
    "learning_parameter = LearningParameter(attr)\n",
    "\n",
    "bot_id = 7777\n",
    "csv_file_path = copied_csv_file_path\n",
    "csv_file_encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-1) 訓練データのTF-IDFベクター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/03/18 PM 02:28:42 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 4114\n",
      "2017/03/18 PM 02:28:42 TextArray#__init__ start\n",
      "2017/03/18 PM 02:28:43 TextArray#to_vec start\n",
      "2017/03/18 PM 02:28:43 TextArray#to_vec end\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    訓練データの生成（内部で TF-IDF 処理を実行）\n",
    "'''\n",
    "from learning.core.training_set.training_message_from_csv import TrainingMessageFromCsv\n",
    "training_set = TrainingMessageFromCsv(bot_id, csv_file_path, learning_parameter, encoding=csv_file_encoding)\n",
    "build_training_set_from_csv = training_set.build()\n",
    "\n",
    "X = build_training_set_from_csv.x\n",
    "y = build_training_set_from_csv.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-2) 外れデータのTF-IDFベクター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/03/18 PM 02:28:43 TextArray#__init__ start\n",
      "2017/03/18 PM 02:28:43 TextArray#to_vec start\n",
      "2017/03/18 PM 02:28:43 TextArray#to_vec end\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    マイオペのプロダクション・コードと同じように、\n",
    "    訓練データ作成時と同じベクトライザーを使用します。\n",
    "'''\n",
    "from learning.core.training_set.text_array import TextArray\n",
    "\n",
    "test_X = [\n",
    "    '人生相談をしたいのですが？', # featureが１件だけ得られるような質問文（ただしmajority）\n",
    "    '何か習い事をしたほうがいいですか？', # featureが３件得られるような質問文\n",
    "    '会社を辞めたいのですが誰に相談するのがいいですか？', # featureが４件得られるような質問文\n",
    "    '有給休暇を取って世界旅行に行きたいと思っています。', # minority featureと判定されそうな質問文\n",
    "    'これは自然言語の機械学習ですか？', # まったくfeatureが得られないような質問文\n",
    "    '難解なプログラミング技術は必須？',\n",
    "]\n",
    "vectorizer = training_set.body_array.vectorizer\n",
    "text_array = TextArray(test_X, vectorizer=vectorizer)\n",
    "\n",
    "'''\n",
    "    外れデータのTF-IDFベクターを取得\n",
    "'''\n",
    "X_error = text_array.to_vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-3) 外れデータのfeatureを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    feature をダンプするためのツール\n",
    "'''\n",
    "def get_item_from_vocabulary(vocabulary, index):\n",
    "    for k, v in vocabulary.items():\n",
    "        if v == index:\n",
    "            return k\n",
    "\n",
    "    return None\n",
    "\n",
    "def dump_features(arr, vocabulary):\n",
    "    features_str = ''\n",
    "\n",
    "    for i, v in enumerate(arr):\n",
    "        if v == 0.0:\n",
    "            continue\n",
    "\n",
    "        if features_str != '':\n",
    "            features_str += ' '\n",
    "        \n",
    "        item = get_item_from_vocabulary(vocabulary, i)\n",
    "        features_str += '%s=%0.3f' % (item, v)\n",
    "\n",
    "    return '[' + features_str + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0[する=1.000]\n",
      "index=1[いい=0.577 する=0.577 何=0.577]\n",
      "index=2[いい=0.500 する=0.500 会社=0.500 誰=0.500]\n",
      "index=3[取る=0.577 思う=0.577 行く=0.577]\n",
      "index=4[]\n",
      "index=5[]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_array._vectorizer.vocabulary_\n",
    "\n",
    "for i, label in enumerate(X_error):\n",
    "    arr = X_error[i].toarray()[0]\n",
    "    dump_str = dump_features(arr, vocabulary)\n",
    "    print('index=%d%s' % (i, dump_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) One-class SVMで学習（複数の手順を使用して比較）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-1) 非線形カーネルを使用（RBF）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma=0.1, kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    One-class SVM with non-linear kernel, anomary is half\n",
    "        fn(i,j) = exp(-gamma*|i-j|^2)\n",
    "'''\n",
    "from sklearn import svm\n",
    "clf_rbf = svm.OneClassSVM(\n",
    "    kernel='rbf', # RBFカーネルを使用\n",
    "    gamma=0.1,    # 係数（デフォルト＝[1/feature数]）\n",
    "    nu=0.5        # 外れ判定される件数の見積もりを全体の5割と想定\n",
    "    ) \n",
    "clf_rbf.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-2) 多項式カーネルを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=1.0, degree=2, gamma=0.1, kernel='poly',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    One-class SVM with Polynomial kernel, anomary is half\n",
    "        fn(i,j) = (gamma*i'*j + coef0)^degree\n",
    "'''\n",
    "from sklearn import svm\n",
    "clf_poly = svm.OneClassSVM(\n",
    "    kernel='poly', # Polynomialカーネルを使用\n",
    "    gamma=0.1,     # 係数 （デフォルト＝[1/feature数]）\n",
    "    coef0=1.0,     # オフセット（デフォルト＝0）\n",
    "    degree=2,      # 乗数（デフォルト＝3）\n",
    "    nu=0.5         # 外れ判定される件数の見積もりを全体の5割と想定\n",
    "    ) \n",
    "clf_poly.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-3) シグモイドカーネルを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.5, degree=3, gamma=0.1, kernel='sigmoid',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    One-class SVM with Sigmoid kernel, anomary is half\n",
    "        fn(i,j) = tanh(gamma*i'*j + coef0)\n",
    "'''\n",
    "from sklearn import svm\n",
    "clf_sigmoid = svm.OneClassSVM(\n",
    "    kernel='sigmoid', # シグモイドカーネルを使用\n",
    "    gamma=0.1,        # 係数（デフォルト＝[1/feature数]）\n",
    "    coef0=0.5,        # オフセット（デフォルト＝0）\n",
    "    nu=0.5            # 外れ判定される件数の見積もりを全体の5割と想定\n",
    "    ) \n",
    "clf_sigmoid.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-4) 線形カーネルを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
       "      kernel='linear', max_iter=-1, nu=0.5, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    One-class SVM with linear kernel, anomary is half\n",
    "        fn(i,j) = i'*j\n",
    "'''\n",
    "from sklearn import svm\n",
    "clf_linear = svm.OneClassSVM(\n",
    "    kernel='linear', # linearカーネルを使用\n",
    "    nu=0.5           # 外れ判定される件数の見積もりを全体の5割と想定\n",
    "    ) \n",
    "clf_linear.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (4) 外れデータを使って予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "カーネルを変更すると、予測結果が若干変わってきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    外れデータを使用して、外れ判定を実行してみます\n",
    "'''\n",
    "y_pred_by_rbf = clf_rbf.predict(X_error)\n",
    "y_pred_by_poly = clf_poly.predict(X_error)\n",
    "y_pred_by_sigmoid = clf_sigmoid.predict(X_error)\n",
    "y_pred_by_linear = clf_linear.predict(X_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 非線形カーネルの場合\n",
    "\n",
    " 明らかに異常な質問文（まったくfeatureが得られないような質問文）に対して、正常と判定されてしまいます。\n",
    " \n",
    " これはプロダクションへの選択肢としては無しかと存じます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -1.,  1.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_by_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 多項式カーネル、シグモイドカーネル、線形カーネルの場合\n",
    "\n",
    " 明らかに異常な質問文は、アノマリーと判定されました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_by_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_by_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_by_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (5) 結論\n",
    "\n",
    "### 非線形カーネル以外のモデルを使用すれば、明らかにおかしい質問文に対して、アノマリー検出できるようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ただし、前述のレポートのとおり、微妙な質問文に対して効果が弱い感じは変わりません。\n",
    "\n",
    "質問文のfeatureが、majority featureに含まれると認識された場合などは、意味的におかしな質問文でも、アノマリー検出されないケースがあるかと存じます。\n",
    "\n",
    "（たとえば [する=1.000] のケースなど）\n",
    "\n",
    "前処理のIDF条件をきつくするなど、極々普遍的なfeatureを制限すれば、回避できる問題かもしれません。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
