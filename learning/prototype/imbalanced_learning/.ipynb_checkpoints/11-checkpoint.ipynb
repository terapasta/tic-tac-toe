{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# One-class SVM の詳細調査（２）\n",
    "\n",
    "scikit-learn の <b>One-class SVM</b> について、カーネル・カスタマイズによる効果を確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) テストデータ／環境準備\n",
    "\n",
    "マイオペで使用しているテストデータ（learning/tests/engine/fixtures/ 配下のCSVファイル）をベースに動作確認を行います。\n",
    "\n",
    "動作確認にあたっては、MySQLdb に接続できないため、ローカル環境テスト用の Bot クラスを使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    テスト環境を準備するためのモジュールを使用します。\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)\n",
    "\n",
    "from prototype.modules import TestTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_benefitone_conversation.csv]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    データファイルは、既存の訓練データを別場所にコピーしてから使用します\n",
    "    テストデータは、csv_file_name で指定したものを使用します。\n",
    "'''\n",
    "csv_file_name = 'test_benefitone_conversation.csv'\n",
    "copied_csv_file_path = TestTool.copy_testdata_csv(learning_dir, csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) TF-IDFベクターの準備\n",
    "\n",
    "Bot クラス内に組み込まれている __build_training_set_from_csv 関数をバラして実行しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    初期設定\n",
    "    データファイル、エンコードを指定\n",
    "    内容は、learn.py を参考にしました。    \n",
    "'''\n",
    "from learning.core.learn.learning_parameter import LearningParameter\n",
    "attr = {\n",
    "    'include_failed_data': False,\n",
    "    'include_tag_vector': False,\n",
    "    'classify_threshold': None,\n",
    "    # 'algorithm': LearningParameter.ALGORITHM_NAIVE_BAYES\n",
    "    'algorithm': LearningParameter.ALGORITHM_LOGISTIC_REGRESSION,\n",
    "    # 'params_for_algorithm': { 'C': 200 }\n",
    "    'params_for_algorithm': {}\n",
    "}\n",
    "learning_parameter = LearningParameter(attr)\n",
    "\n",
    "bot_id = 7777\n",
    "csv_file_path = copied_csv_file_path\n",
    "csv_file_encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-1) 訓練データのTF-IDFベクター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/03/20 PM 04:01:05 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 4114\n",
      "2017/03/20 PM 04:01:05 TextArray#__init__ start\n",
      "2017/03/20 PM 04:01:07 TextArray#to_vec start\n",
      "2017/03/20 PM 04:01:07 TextArray#to_vec end\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    訓練データの生成（内部で TF-IDF 処理を実行）\n",
    "'''\n",
    "from learning.core.training_set.training_message_from_csv import TrainingMessageFromCsv\n",
    "training_set = TrainingMessageFromCsv(bot_id, csv_file_path, learning_parameter, encoding=csv_file_encoding)\n",
    "build_training_set_from_csv = training_set.build()\n",
    "\n",
    "X = build_training_set_from_csv.x\n",
    "y = build_training_set_from_csv.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-2) 外れデータのTF-IDFベクター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/03/20 PM 04:01:07 TextArray#__init__ start\n",
      "2017/03/20 PM 04:01:07 TextArray#to_vec start\n",
      "2017/03/20 PM 04:01:07 TextArray#to_vec end\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    マイオペのプロダクション・コードと同じように、\n",
    "    訓練データ作成時と同じベクトライザーを使用します。\n",
    "'''\n",
    "from learning.core.training_set.text_array import TextArray\n",
    "\n",
    "test_X = [\n",
    "    '人生相談をしたいのですが？', # featureが１件だけ得られるような質問文（ただしmajority）\n",
    "    '何か習い事をしたほうがいいですか？', # featureが３件得られるような質問文\n",
    "    '会社を辞めたいのですが誰に相談するのがいいですか？', # featureが４件得られるような質問文\n",
    "    '有給休暇を取って世界旅行に行きたいと思っています。', # minority featureと判定されそうな質問文\n",
    "    'これは自然言語の機械学習ですか？', # まったくfeatureが得られないような質問文\n",
    "    '難解なプログラミング技術は必須？',\n",
    "]\n",
    "vectorizer = training_set.body_array.vectorizer\n",
    "text_array = TextArray(test_X, vectorizer=vectorizer)\n",
    "\n",
    "'''\n",
    "    外れデータのTF-IDFベクターを取得\n",
    "'''\n",
    "X_error = text_array.to_vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-3) 外れデータのfeatureを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    feature をダンプするためのツール\n",
    "'''\n",
    "def get_item_from_vocabulary(vocabulary, index):\n",
    "    for k, v in vocabulary.items():\n",
    "        if v == index:\n",
    "            return k\n",
    "\n",
    "    return None\n",
    "\n",
    "def dump_features(arr, vocabulary):\n",
    "    features_str = ''\n",
    "\n",
    "    for i, v in enumerate(arr):\n",
    "        if v == 0.0:\n",
    "            continue\n",
    "\n",
    "        if features_str != '':\n",
    "            features_str += ' '\n",
    "        \n",
    "        item = get_item_from_vocabulary(vocabulary, i)\n",
    "        features_str += '%s=%0.3f' % (item, v)\n",
    "\n",
    "    return '[' + features_str + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0[する=1.000]\n",
      "index=1[いい=0.577 する=0.577 何=0.577]\n",
      "index=2[いい=0.500 する=0.500 会社=0.500 誰=0.500]\n",
      "index=3[取る=0.577 思う=0.577 行く=0.577]\n",
      "index=4[]\n",
      "index=5[]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_array._vectorizer.vocabulary_\n",
    "\n",
    "for i, label in enumerate(X_error):\n",
    "    arr = X_error[i].toarray()[0]\n",
    "    dump_str = dump_features(arr, vocabulary)\n",
    "    print('index=%d%s' % (i, dump_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) One-class SVMで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-1) カスタムカーネルの定義\n",
    "\n",
    "<b>線形カーネルをベースにカスタマイズ</b>したカーネルを使用して確認してみます。\n",
    "\n",
    "こちらを参考にしました。\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html#custom-kernels\n",
    "\n",
    "ここでは、０件ないし１件しか feature が存在しないサンプルを、アノマリーとして検出させる事例を設定してみました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    カスタムカーネル\n",
    "    引数：サンプル２件が引数となります\n",
    "    戻り値：[feature数 * feature数] の行列\n",
    "'''\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "def clear_features(matrix):\n",
    "    n_sample = matrix.shape[0]\n",
    "    n_feature = matrix.shape[1]\n",
    "    print(\"check_features: sample=%d, feature=%d\" % (n_sample, n_feature))\n",
    "    \n",
    "    for i in range(0, n_sample):\n",
    "        row = matrix.getrow(i)\n",
    "        cnt_feature = row.getnnz()\n",
    "        if cnt_feature > 1:\n",
    "            continue # feature が２件以上あるサンプルはパス\n",
    "\n",
    "        # feature が１件以下の場合は、全列をゼロクリア\n",
    "        print(\"Detected as anomary: index=%d, feature count=%d\" % (i, cnt_feature))\n",
    "        matrix[i] = csr_matrix((1, n_feature))\n",
    "\n",
    "def svm_custom_kernel(X, Y):\n",
    "    # feature数が２件未満のサンプルは、feature が無いものと扱い、\n",
    "    # 一律アノマリーと判定させます <---これはひとつの例です\n",
    "    print(type(X))\n",
    "    clear_features(X)\n",
    "    \n",
    "    # 線形カーネルと同様に演算します\n",
    "    return np.dot(X, Y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (3-2) One-class SVMに、カスタムカーネルを使用するよう指定\n",
    "\n",
    "訓練データの中にも、カスタムカーネルに引っかかってしまう（＝featureが１件しかない）サンプルがあるのが気になりますが・・・あくまでもカスタムカーネルの効果を確認するための例ですので、ここでは静観します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "check_features: sample=4114, feature=646\n",
      "Detected as anomary: index=26, feature count=1\n",
      "Detected as anomary: index=285, feature count=1\n",
      "Detected as anomary: index=286, feature count=1\n",
      "Detected as anomary: index=287, feature count=1\n",
      "Detected as anomary: index=511, feature count=1\n",
      "Detected as anomary: index=512, feature count=1\n",
      "Detected as anomary: index=513, feature count=1\n",
      "Detected as anomary: index=622, feature count=1\n",
      "Detected as anomary: index=655, feature count=1\n",
      "Detected as anomary: index=658, feature count=1\n",
      "Detected as anomary: index=661, feature count=1\n",
      "Detected as anomary: index=664, feature count=1\n",
      "Detected as anomary: index=789, feature count=1\n",
      "Detected as anomary: index=1013, feature count=1\n",
      "Detected as anomary: index=1090, feature count=1\n",
      "Detected as anomary: index=1093, feature count=1\n",
      "Detected as anomary: index=1117, feature count=1\n",
      "Detected as anomary: index=1119, feature count=1\n",
      "Detected as anomary: index=1135, feature count=1\n",
      "Detected as anomary: index=1186, feature count=1\n",
      "Detected as anomary: index=1244, feature count=1\n",
      "Detected as anomary: index=1260, feature count=1\n",
      "Detected as anomary: index=1261, feature count=1\n",
      "Detected as anomary: index=1318, feature count=1\n",
      "Detected as anomary: index=1320, feature count=1\n",
      "Detected as anomary: index=1321, feature count=1\n",
      "Detected as anomary: index=1326, feature count=1\n",
      "Detected as anomary: index=1330, feature count=1\n",
      "Detected as anomary: index=1435, feature count=1\n",
      "Detected as anomary: index=1488, feature count=1\n",
      "Detected as anomary: index=1691, feature count=1\n",
      "Detected as anomary: index=1732, feature count=1\n",
      "Detected as anomary: index=1771, feature count=1\n",
      "Detected as anomary: index=1774, feature count=1\n",
      "Detected as anomary: index=1783, feature count=1\n",
      "Detected as anomary: index=1788, feature count=1\n",
      "Detected as anomary: index=1794, feature count=1\n",
      "Detected as anomary: index=1795, feature count=1\n",
      "Detected as anomary: index=1822, feature count=1\n",
      "Detected as anomary: index=1840, feature count=1\n",
      "Detected as anomary: index=1841, feature count=1\n",
      "Detected as anomary: index=1947, feature count=1\n",
      "Detected as anomary: index=1948, feature count=1\n",
      "Detected as anomary: index=1950, feature count=1\n",
      "Detected as anomary: index=1952, feature count=1\n",
      "Detected as anomary: index=2223, feature count=1\n",
      "Detected as anomary: index=2224, feature count=1\n",
      "Detected as anomary: index=2225, feature count=1\n",
      "Detected as anomary: index=2334, feature count=1\n",
      "Detected as anomary: index=2367, feature count=1\n",
      "Detected as anomary: index=2370, feature count=1\n",
      "Detected as anomary: index=2373, feature count=1\n",
      "Detected as anomary: index=2376, feature count=1\n",
      "Detected as anomary: index=2501, feature count=1\n",
      "Detected as anomary: index=2725, feature count=1\n",
      "Detected as anomary: index=2802, feature count=1\n",
      "Detected as anomary: index=2805, feature count=1\n",
      "Detected as anomary: index=2829, feature count=1\n",
      "Detected as anomary: index=2831, feature count=1\n",
      "Detected as anomary: index=2847, feature count=1\n",
      "Detected as anomary: index=2898, feature count=1\n",
      "Detected as anomary: index=2956, feature count=1\n",
      "Detected as anomary: index=2972, feature count=1\n",
      "Detected as anomary: index=2973, feature count=1\n",
      "Detected as anomary: index=3030, feature count=1\n",
      "Detected as anomary: index=3032, feature count=1\n",
      "Detected as anomary: index=3033, feature count=1\n",
      "Detected as anomary: index=3038, feature count=1\n",
      "Detected as anomary: index=3042, feature count=1\n",
      "Detected as anomary: index=3147, feature count=1\n",
      "Detected as anomary: index=3200, feature count=1\n",
      "Detected as anomary: index=3403, feature count=1\n",
      "Detected as anomary: index=3444, feature count=1\n",
      "Detected as anomary: index=3483, feature count=1\n",
      "Detected as anomary: index=3486, feature count=1\n",
      "Detected as anomary: index=3495, feature count=1\n",
      "Detected as anomary: index=3500, feature count=1\n",
      "Detected as anomary: index=3506, feature count=1\n",
      "Detected as anomary: index=3507, feature count=1\n",
      "Detected as anomary: index=3534, feature count=1\n",
      "Detected as anomary: index=3552, feature count=1\n",
      "Detected as anomary: index=3553, feature count=1\n",
      "Detected as anomary: index=3659, feature count=1\n",
      "Detected as anomary: index=3660, feature count=1\n",
      "Detected as anomary: index=3662, feature count=1\n",
      "Detected as anomary: index=3664, feature count=1\n",
      "Detected as anomary: index=3826, feature count=1\n",
      "Detected as anomary: index=4085, feature count=1\n",
      "Detected as anomary: index=4086, feature count=1\n",
      "Detected as anomary: index=4087, feature count=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
       "      kernel=<function svm_custom_kernel at 0x10a8b3ea0>, max_iter=-1,\n",
       "      nu=0.5, random_state=None, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    One-class SVM with customized kernel, anomary is checked in kernel\n",
    "'''\n",
    "from sklearn import svm\n",
    "clf_custom = svm.OneClassSVM(\n",
    "    kernel=svm_custom_kernel # カスタムカーネルを使用\n",
    "    ) \n",
    "clf_custom.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (4) 外れデータを使って予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "check_features: sample=6, feature=646\n",
      "Detected as anomary: index=0, feature count=1\n",
      "Detected as anomary: index=4, feature count=0\n",
      "Detected as anomary: index=5, feature count=0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    外れデータを使用して、外れ判定を実行してみます\n",
    "'''\n",
    "y_pred_by_custom = clf_custom.predict(X_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "明らかに異常とみられる質問文 (index=0, 4, 5) に対しては、アノマリーと判定されることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_by_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (5) 結論\n",
    "\n",
    "#### 線形カーネルをベースにカスタマイズしたカーネルを使用しても、アノマリー検出は可能なようです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ただし、微妙な質問文に対して効果を得るには、所定の基準及び判定が必要となってしまいそうです。\n",
    "\n",
    "(たとえば単体出現NGワードを設定しておいて、該当する場合にアノマリーと検出させるようなロジックにする、etc...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
