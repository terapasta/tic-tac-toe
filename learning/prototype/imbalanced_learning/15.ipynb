{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# One-class SVM における誤検出率（nu=0.5時）\n",
    "\n",
    "scikit-learn の <b>One-class SVM</b> の、誤検出率（アノマリーでないデータがアノマリーと検出されてしまう率）を求める方法の検討になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (0) 確認結果\n",
    "\n",
    "結果から申し上げると、誤検出率は、パラメータの nu 値（0.5）とほぼ同じ結果（0.499）となり、これだけを見ると<B>「実用が困難」</B>という判断になってしまうかと存じます。\n",
    "\n",
    "ですので、<a href=\"16.ipynb\"><b>こちらのレポート</b></a>で、パラメータ nu=0.01 に下げた実験を行なっております。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) テストデータ／環境準備\n",
    "\n",
    "マイオペで使用しているテストデータ（learning/tests/engine/fixtures/ 配下のCSVファイル）をベースに動作確認を行います。\n",
    "\n",
    "動作確認にあたっては、MySQLdb に接続できないため、ローカル環境テスト用の Bot クラスを使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    テスト環境を準備するためのモジュールを使用します。\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "learning_dir = os.path.abspath(\"../../\") #<--- donusagi-bot/learning\n",
    "os.chdir(learning_dir)\n",
    "\n",
    "if learning_dir not in sys.path:\n",
    "    sys.path.append(learning_dir)\n",
    "\n",
    "from prototype.modules import TestTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_benefitone_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_daikin_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_ptna_conversation.csv]\n",
      "CSV file for test=[/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_septeni_conversation.csv]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_benefitone_conversation.csv',\n",
       " '/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_daikin_conversation.csv',\n",
       " '/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_ptna_conversation.csv',\n",
       " '/Users/makmorit/GitHub/donusagi-bot/learning/prototype/resources/test_septeni_conversation.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    データファイルは、既存の訓練データを別場所にコピーしてから使用します\n",
    "    テストデータは、csv_file_name で指定した複数件のファイルを使用します。\n",
    "'''\n",
    "csv_file_names = [\n",
    "    'test_benefitone_conversation.csv',\n",
    "    'test_daikin_conversation.csv',\n",
    "    'test_ptna_conversation.csv',\n",
    "    'test_septeni_conversation.csv'\n",
    "]\n",
    "copied_csv_file_paths = TestTool.copy_testdata_csv(learning_dir, csv_file_names)\n",
    "copied_csv_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) TF-IDFベクターの準備\n",
    "\n",
    "Bot クラス内に組み込まれている __build_training_set_from_csv 関数をバラして実行しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    初期設定\n",
    "    データファイル、エンコードを指定\n",
    "    内容は、learn.py を参考にしました。    \n",
    "'''\n",
    "from learning.core.learn.learning_parameter import LearningParameter\n",
    "attr = {\n",
    "    'include_failed_data': False,\n",
    "    'include_tag_vector': False,\n",
    "    'classify_threshold': None,\n",
    "    # 'algorithm': LearningParameter.ALGORITHM_NAIVE_BAYES\n",
    "    'algorithm': LearningParameter.ALGORITHM_LOGISTIC_REGRESSION,\n",
    "    # 'params_for_algorithm': { 'C': 200 }\n",
    "    'params_for_algorithm': {}\n",
    "}\n",
    "learning_parameter = LearningParameter(attr)\n",
    "\n",
    "bot_id = 7777\n",
    "csv_file_encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-1) 訓練データのTF-IDFベクター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/03/23 PM 09:27:38 TrainingMessageFromCsv#__build_learning_training_messages count of learning data: 28272\n",
      "2017/03/23 PM 09:27:38 TextArray#__init__ start\n",
      "2017/03/23 PM 09:27:52 TextArray#to_vec start\n",
      "2017/03/23 PM 09:27:53 TextArray#to_vec end\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    訓練データの生成（内部で TF-IDF 処理を実行）\n",
    "    \n",
    "    text_array.py における TF-IDF 処理では、\n",
    "    以下の通り「する」をストップワード化指定しております\n",
    "    \n",
    "    class TextArray:\n",
    "        :\n",
    "        def __build_vectorizer(self):\n",
    "            :\n",
    "            vectorizer = TfidfVectorizer(use_idf=False, token_pattern=u'(?u)\\\\b\\\\w+\\\\b', stop_words=['する'])\n",
    "'''\n",
    "#from learning.core.training_set.training_message_from_csv import TrainingMessageFromCsv\n",
    "from prototype.modules.training_message_from_csv import TrainingMessageFromCsv\n",
    "training_set = TrainingMessageFromCsv(bot_id, copied_csv_file_paths, learning_parameter, encoding=csv_file_encoding)\n",
    "build_training_set_from_csv = training_set.build()\n",
    "\n",
    "X = build_training_set_from_csv.x\n",
    "y = build_training_set_from_csv.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample=28272, feature=2748\n"
     ]
    }
   ],
   "source": [
    "n_sample = X.shape[0]\n",
    "n_feature = X.shape[1]\n",
    "print(\"sample=%d, feature=%d\" % (n_sample, n_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-2) 外れデータのTF-IDFベクター\n",
    "\n",
    "<b><a href=\"12.ipynb\">こちらで再検証した時と同じ質問文</a></b>をつかっております。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017/03/23 PM 09:27:53 TextArray#__init__ start\n",
      "2017/03/23 PM 09:27:53 TextArray#to_vec start\n",
      "2017/03/23 PM 09:27:53 TextArray#to_vec end\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    マイオペのプロダクション・コードと同じように、\n",
    "    訓練データ作成時と同じベクトライザーを使用します。\n",
    "'''\n",
    "#from learning.core.training_set.text_array import TextArray\n",
    "from prototype.modules.text_array import TextArray\n",
    "\n",
    "test_X = [\n",
    "    '要素技術は自然languageの機械learningですか？', # まったくfeatureが抽出されない質問文\n",
    "\n",
    "    '人生相談をしたいのですが？', # featureが１件抽出されるな質問文「する」を含む\n",
    "    '難解なプログラミング技術を調達？', # featureが１件抽出される質問文「する」を含まない\n",
    "\n",
    "    '何か習い事をしますか？', # featureが２件抽出される質問文「する」を含む\n",
    "    '何か習い事がいいですか？', # featureが２件抽出される質問文「する」を含まない\n",
    "    \n",
    "    '何か習い事をしたほうがいいですか？', # featureが３件抽出される質問文「する」を含む\n",
    "    '何か習い事を行うほうがいいですか？', # featureが３件抽出される質問文「する」を含まない\n",
    "    \n",
    "    '会社を辞めたいのですが誰に相談するのがいいですか？', # featureが４件抽出される質問文「する」を含む\n",
    "    '会社を辞めたいのですが誰に相談を行うのがいいですか？', # featureが４件抽出される質問文「する」を含まない\n",
    "\n",
    "    '有給休暇を取って海外に行き旅行する意向があります。', # featureが５件抽出される質問文「する」を含む\n",
    "    '有給休暇を取って海外に行きたいと思っています。', # featureが５件抽出される質問文「する」を含まない\n",
    "]\n",
    "vectorizer = training_set.body_array.vectorizer\n",
    "text_array = TextArray(test_X, vectorizer=vectorizer)\n",
    "\n",
    "'''\n",
    "    外れデータのTF-IDFベクターを取得\n",
    "'''\n",
    "X_error = text_array.to_vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0[]\n",
      "index=1[]\n",
      "index=2[調達=1.000]\n",
      "index=3[何=1.000]\n",
      "index=4[いい=0.707 何=0.707]\n",
      "index=5[いい=0.707 何=0.707]\n",
      "index=6[いい=0.577 何=0.577 行う=0.577]\n",
      "index=7[いい=0.577 会社=0.577 誰=0.577]\n",
      "index=8[いい=0.500 会社=0.500 行う=0.500 誰=0.500]\n",
      "index=9[休暇=0.500 取る=0.500 海外=0.500 行く=0.500]\n",
      "index=10[休暇=0.447 取る=0.447 思う=0.447 海外=0.447 行く=0.447]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_array._vectorizer.vocabulary_\n",
    "dumped_features = TestTool.get_dumped_features(X_error, vocabulary)\n",
    "for d in dumped_features:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (3) One-class SVMで学習\n",
    "\n",
    "線形カーネルを使用しています。パラメータはデフォルトになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
       "      kernel='linear', max_iter=-1, nu=0.5, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    One-class SVM with linear kernel, anomary is half\n",
    "        fn(i,j) = i'*j\n",
    "'''\n",
    "from sklearn import svm\n",
    "clf_linear = svm.OneClassSVM(\n",
    "    kernel='linear', # linearカーネルを使用\n",
    "    nu=0.5           # 外れ判定される件数の見積もりを全体の5割と想定\n",
    "    ) \n",
    "clf_linear.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (4) 誤検出率の算定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-1) 訓練データを使って予測実行\n",
    "\n",
    "アノマリーでないデータ＝訓練データを使って予測した時、アノマリーと検出されてしまうデータがあるかどうか確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    訓練データを使用して、外れ判定を実行してみます\n",
    "'''\n",
    "pred_by_linear_for_train = clf_linear.predict(X)\n",
    "pred_by_linear_for_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-2) 誤検出率を算出\n",
    "\n",
    "誤検出率＝アノマリー検出件数 ÷ 訓練データ件数 になります。\n",
    "\n",
    "パラメータの nu 値（デフォルト=0.5）とほぼ同じになるため、モデルとしては正しいという事は分かります。\n",
    "\n",
    "ただし、その事が判断基準というのはあり得ないかと存じます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "誤検出率=0.499 [サンプル件数=28272, アノマリー件数=14108]\n"
     ]
    }
   ],
   "source": [
    "n_anomaly = len([c for c in pred_by_linear_for_train if c == -1])\n",
    "\n",
    "print('誤検出率=%0.3f [サンプル件数=%d, アノマリー件数=%d]' % (n_anomaly / n_sample, n_sample, n_anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-3) 参考：アノマリーと検出された訓練データだけを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14108x2748 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 64664 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    (4-1) において、アノマリーと検出されたデータを抽出\n",
    "'''\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "X_misdetected_temp = lil_matrix((n_anomaly, n_feature))\n",
    "idx = 0\n",
    "for i, v in enumerate(pred_by_linear_for_train):\n",
    "    if v == -1:\n",
    "        X_misdetected_temp[idx] = X.getrow(i)\n",
    "        idx += 1\n",
    "        \n",
    "X_misdetected = X_misdetected_temp.tocsr()\n",
    "X_misdetected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (4-4) 参考：アノマリーと検出された訓練データだけを使って予測したら、結果はどうなるか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 全て外れとなります（当たり前ですが）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    外れと判定されてしまった訓練データだけを使用して、\n",
    "    再度、外れ判定を実行してみます\n",
    "'''\n",
    "pred_by_linear_for_train_2 = clf_linear.predict(X_misdetected)\n",
    "pred_by_linear_for_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "誤検出率=1.000 [サンプル件数=14108, アノマリー件数=14108]\n"
     ]
    }
   ],
   "source": [
    "n_anomaly_2 = len([c for c in pred_by_linear_for_train_2 if c == -1])\n",
    "\n",
    "print('誤検出率=%0.3f [サンプル件数=%d, アノマリー件数=%d]' % (n_anomaly_2 / n_anomaly, n_anomaly, n_anomaly_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (5) 参考：外れデータを使って予測\n",
    "\n",
    "#### 結果として全て外れとなったのは、nu=0.5 の指定により、外れ判定が緩くなったためと推測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    外れデータを使用して、外れ判定を実行してみます\n",
    "'''\n",
    "pred_by_linear_for_error = clf_linear.predict(X_error)\n",
    "pred_by_linear_for_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
