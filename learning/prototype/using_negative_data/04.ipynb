{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 正則化オプションの効果確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "scikit-learn のロジスティック回帰モジュールに正規化オプションを指定し、実行させる例を下記に掲載いたします。\n",
    "\n",
    "使い方および効果としては、\n",
    "\n",
    "\n",
    "- class_weight（インスタンス生成時引数）\n",
    "\n",
    "  クラスごとに重み付けを与える\n",
    "  （クラス＝質問文から選択された回答文と等価）\n",
    "\n",
    "  <b>オーバーサンプリング気味のクラスに対し、ペナルティを重くし、該当クラスが誤選択されることを回避</b>させる効果があります。\n",
    "\n",
    "\n",
    "- sample_weight（学習実行時引数）\n",
    "\n",
    "  訓練データごとに重み付けを与える\n",
    "  （訓練データ＝質問文１件と等価）\n",
    "\n",
    "  <b>特異な特徴をもつ訓練データが、同一クラスに混在する場合、ペナルティを重くし、該当クラスが誤選択されることを回避</b>させる効果があります。\n",
    "\n",
    "\n",
    "となるかと存じます。\n",
    "\n",
    "\n",
    "こちらの例では、効果がわかりやすくなるように、あえて極端な例を設定して実行させています。\n",
    "\n",
    "なにとぞ、ご容赦ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (1) class_weight の効果確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### テスト準備\n",
    "\n",
    "長いので適宜読み飛ばしていただければ幸いです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 50 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "tf_vector_array = array([\n",
    "    [1, 0, 0, 0, 1], # １番目のクラス\n",
    "    [1, 0, 0, 0, 1], #（特徴として、1番目の特徴語が必ず存在）\n",
    "    [1, 0, 0, 2, 0], # オーバーサンプリングの例として、他のクラスの５倍のレコードを用意しています。\n",
    "    [1, 1, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [1, 1, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 0, 1],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [1, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 1, 0],\n",
    "\n",
    "    [0, 1, 0, 1, 0], # ２番目のクラス\n",
    "    [0, 1, 0, 1, 0], #（特徴として、1,3,5番目の特徴語が欠落）\n",
    "    [0, 1, 0, 1, 0],\n",
    "\n",
    "    [0, 0, 1, 1, 0], # ３番目のクラス\n",
    "    [0, 0, 1, 1, 0], # （特徴として、1,2,5番目の特徴語が欠落）\n",
    "    [0, 0, 1, 1, 0]\n",
    "    ])\n",
    "tf_vector = csr_matrix(tf_vector_array) # これは特徴語の出現回数リストです。\n",
    "tf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vector_array = array([\n",
    "    1, # １番目のクラス\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "\n",
    "    2, # ２番目のクラス\n",
    "    2,\n",
    "    2,\n",
    "\n",
    "    3, # ３番目のクラス\n",
    "    3,\n",
    "    3\n",
    "    ])\n",
    "class_vector_array # これは質問文ごとのクラスリスト（分類ラベルリスト）です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 質問文を作成\n",
    "\n",
    "訓練データに近い内容にしておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0.9,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  1.1,  0. ,  0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vector_array_test = array([\n",
    "    [1.1, 0, 0, 0, 0], # これはクラス＝１想定\n",
    "    [0, 0.9, 0, 0, 0], # これはクラス＝２想定（特徴として、1,3,5番目の特徴語が欠落）\n",
    "    [0, 0, 1.1, 0, 0]  # これはクラス＝３想定（特徴として、1,2,5番目の特徴語が欠落）\n",
    "    ])\n",
    "tf_vector_test = csr_matrix(tf_vector_array_test) # これは特徴語の出現回数リストです。\n",
    "tf_vector_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1-a) class_weight の指定を省略した場合\n",
    "\n",
    "#### インスタンスを生成→学習実行\n",
    "\n",
    "まずは、オーバーサンプリング時の動きをみるため、クラスごとに重み付け定義を、引数として指定しないようにします。\n",
    "\n",
    "LogisticRegression インスタンスを生成し、学習を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression_noweight = LogisticRegression(\n",
    "                        class_weight=None, # <---重み付け定義を指定しない\n",
    "                        max_iter=100,\n",
    "                        solver='newton-cg',\n",
    "                        )\n",
    "logisticRegression_noweight.fit(tf_vector, class_vector_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 予測結果\n",
    "\n",
    "２番目、３番目の質問に対し、<b>オーバーサンプリングされた１番目のクラスが誤選択されてしまう</b>ことが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88487469,  0.06026079,  0.05486453],\n",
       "       [ 0.44667468,  0.4222523 ,  0.13107302],\n",
       "       [ 0.45818323,  0.10326291,  0.43855386]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zp = logisticRegression_noweight.predict_proba(tf_vector_test)\n",
    "Zp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (1-b) class_weight を指定した場合\n",
    "\n",
    "クラスごとに重み付け定義を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.2, 2: 1.0, 3: 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {# <---ご注意：class_weight は dictionary です\n",
    "    1: 0.2, # <---他のクラスに対して、５分の１の重み付けがされています \n",
    "    2: 1.0,\n",
    "    3: 1.0\n",
    "    }\n",
    "class_weight # これはクラスごとの重み付け定義リストです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### インスタンスを生成→学習実行\n",
    "\n",
    "class_weight を指定し、学習を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={1: 0.2, 2: 1.0, 3: 1.0}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='newton-cg', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(\n",
    "                        penalty ='l2', # <---L2正則化が効くようにします\n",
    "                        C       = 0.1, # <---正則化の効きを大きくします\n",
    "                        class_weight=class_weight, # <---重み付け定義を指定\n",
    "                        max_iter=100,\n",
    "                        solver='newton-cg',\n",
    "                        )\n",
    "logisticRegression.fit(tf_vector, class_vector_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 予測結果\n",
    "\n",
    "２番目、３番目の質問に対し、こんどは<b>オーバーサンプリングされた１番目のクラスへの誤選択が回避される</b>ことが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38547003,  0.3078865 ,  0.30664348],\n",
       "       [ 0.32771352,  0.36460199,  0.30768449],\n",
       "       [ 0.3282186 ,  0.30238248,  0.36939892]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zp = logisticRegression.predict_proba(tf_vector_test)\n",
    "Zp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## (2) sample_weight の効果確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### テスト準備\n",
    "\n",
    "長いので適宜読み飛ばしていただければ幸いです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "tf_vector_array = array([\n",
    "    [1, 0, 0, 1, 1], # １番目のクラス\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [0, 1, 0, 4, 0], # 特異な特徴をもつ例。このデータだけ４番目の特徴が抜きん出ています。\n",
    "\n",
    "    [0, 1, 0, 1, 0], # ２番目のクラス\n",
    "    [0, 1, 0, 1, 0], #（特徴として、1,3,5番目の特徴語が欠落）\n",
    "    [0, 1, 0, 1, 0],\n",
    "\n",
    "    [0, 0, 1, 1, 0], # ３番目のクラス\n",
    "    [0, 0, 1, 1, 0], # （特徴として、1,2,5番目の特徴語が欠落）\n",
    "    [0, 0, 1, 1, 0]\n",
    "    ])\n",
    "tf_vector = csr_matrix(tf_vector_array) # これは特徴語の出現回数リストです。\n",
    "tf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 2, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vector_array = array([\n",
    "    1, # １番目のクラス\n",
    "    1,\n",
    "    1,\n",
    "\n",
    "    2, # ２番目のクラス\n",
    "    2,\n",
    "    2,\n",
    "\n",
    "    3, # ３番目のクラス\n",
    "    3,\n",
    "    3\n",
    "    ])\n",
    "class_vector_array # これは質問文ごとのクラスリスト（分類ラベルリスト）です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 質問文を作成\n",
    "\n",
    "訓練データに近い内容にしておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3,  0. ,  0. ,  1.1,  1. ],\n",
       "       [ 0. ,  1.2,  0. ,  4. ,  0. ],\n",
       "       [ 0. ,  0. ,  1.1,  0. ,  0. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vector_array_test = array([\n",
    "    [1.3, 0,   0,   1.1, 1],  # これはクラス＝１想定\n",
    "    [0,   1.2, 0,   4,   0],  # これはクラス＝２想定（ただし４番目の特徴がつよく、クラス１に誤選択される可能性あり）\n",
    "    [0,   0,   1.1, 0,   0]   # これはクラス＝３想定\n",
    "    ])\n",
    "tf_vector_test = csr_matrix(tf_vector_array_test) # これは特徴語の出現回数リストです。\n",
    "tf_vector_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-a) sample_weight の指定を省略した場合\n",
    "\n",
    "#### インスタンスを生成→学習実行\n",
    "\n",
    "まずは、際立って特徴が強い訓練データが混在した時の動きをみるため、重み付け定義を引数として指定しないようにします。\n",
    "\n",
    "LogisticRegression インスタンスを生成し、学習を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression_noweight = LogisticRegression(\n",
    "                        penalty ='l2', # <---L2正則化が効くようにします\n",
    "                        C       = 0.1, # <---正則化の効きを大きくします\n",
    "                        class_weight=None, # <---クラスごとの重み付け定義は指定しない\n",
    "                        max_iter=100,\n",
    "                        solver='newton-cg',\n",
    "                        )\n",
    "logisticRegression_noweight.fit(tf_vector, class_vector_array, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 予測結果\n",
    "\n",
    "２番目の質問に対し、２番目のクラスではなく<b>１番目のクラスが誤選択されてしまう</b>ことが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3867104 ,  0.30419486,  0.30909475],\n",
       "       [ 0.42434836,  0.31542201,  0.26022964],\n",
       "       [ 0.26046137,  0.33293679,  0.40660184]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zp = logisticRegression_noweight.predict_proba(tf_vector_test)\n",
    "Zp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (2-b) sample_weight を指定した場合\n",
    "\n",
    "訓練データごとに重み付け定義を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1. ,  1. ,  0.3,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = array([ # <---ご注意：sample_weight は array です\n",
    "    1.0,\n",
    "    1.0,\n",
    "    0.3, # [0, 1, 0, 4, 0] という特徴を持った訓練データ（クラス＝１）の重み付けを下げます\n",
    "\n",
    "    1.0,\n",
    "    1.0,\n",
    "    1.0,\n",
    "\n",
    "    1.0,\n",
    "    1.0,\n",
    "    1.0\n",
    "    ])\n",
    "sample_weight # これは訓練データごとの重み付け定義リストです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "#### インスタンスを生成→学習\n",
    "\n",
    "sample_weight を指定し、学習を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(\n",
    "                        penalty ='l2', # <---L2正則化が効くようにします\n",
    "                        C       = 0.1, # <---正則化の効きを大きくします\n",
    "                        class_weight=None, # <---クラスごとの重み付け定義は指定しない\n",
    "                        max_iter=100,\n",
    "                        solver='newton-cg',\n",
    "                        )\n",
    "logisticRegression.fit(tf_vector, class_vector_array, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 予測の実行\n",
    "\n",
    "２番目の質問文に対し、先ほどクラス＝１と回答されたところが、sample_weight 指定により<b>回答が回避されてしまう</b>ことが確認できます。\n",
    "\n",
    "他の質問文は、概ね想定通りに分類されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34057261,  0.32873334,  0.33069405],\n",
       "       [ 0.29741429,  0.38663726,  0.31594845],\n",
       "       [ 0.24232558,  0.3423744 ,  0.41530002]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zp = logisticRegression.predict_proba(tf_vector_test)\n",
    "Zp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
